{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Diagramming Tool\n",
    "#### **Instructions for Use**:\n",
    "1. Define `dish_indexes` and update configurations in the **tracked devices and pods** cell.\n",
    "2. Run the notebook in sequential order:\n",
    "   - Start by setting up the environment and tracked devices.\n",
    "   - Enter the event printer context to monitor events.\n",
    "   - Execute your tests or commands on the SUT.\n",
    "   - Exit the event printer to stop monitoring.\n",
    "   - Retrieve logs and parse them into a sequence diagram.\n",
    "3. View or render the generated `.puml` file using a PlantUML-compatible viewer.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is designed to streamline the analysis of the entire system by visualising interactions through sequence diagrams, making it easier to debug and understand system behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import tango\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime, timezone\n",
    "from typing import Tuple, List, Match\n",
    "from ska_mid_jupyter_notebooks.helpers.configuration import get_dish_namespace\n",
    "from notebook_tools.sequence_diagram_setup import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tracked devices and pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dish indexes to use\n",
    "dish_indexes = ['001', '036', '063', '100']\n",
    "\n",
    "# Define namespaces\n",
    "sut_namespace = 'staging'\n",
    "dish_namespaces = [get_dish_namespace(sut_namespace, f'SKA{index}') for index in dish_indexes]\n",
    "\n",
    "tracked_device_trls = define_tracked_device_trls(dish_indexes, sut_namespace, dish_namespaces)\n",
    "namespaces_pods = define_pods_for_logs(dish_indexes, sut_namespace, dish_namespaces)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up device hierarchies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_hierarchy = setup_device_hierarchy(dish_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PlantUML helper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantUMLSequenceDiagram:\n",
    "    def __init__(self):\n",
    "        self.diagram_code = \"\"\n",
    "\n",
    "    def start_diagram(self, title, actor):\n",
    "        self.diagram_code = \"@startuml SequenceDiagram\\n\"\n",
    "        self.diagram_code += 'skinparam ParticipantPadding 10\\n'\n",
    "        self.diagram_code += f\"title {title}\\n\"\n",
    "        self.diagram_code += f\"actor {actor}\\n\"\n",
    "\n",
    "    def add_participant(self, participant):\n",
    "        self.diagram_code += f\"participant {self.clean_text(participant)}\\n\"\n",
    "\n",
    "    def add_box(self, box_name, colour):\n",
    "        self.diagram_code += f'box {box_name} #{colour}\\n'\n",
    "\n",
    "    def end_box(self):\n",
    "        self.diagram_code += 'end box\\n'\n",
    "\n",
    "    def end_diagram(self):\n",
    "        self.diagram_code += \"@enduml\"\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        return text.replace(\"-\", \"_\")\n",
    "\n",
    "    def wrap_text(self, text, max_width=30, max_length=500):\n",
    "        if max_width <= 0:\n",
    "            raise ValueError(\"max_width must be a positive integer.\")\n",
    "\n",
    "        if len(text) > max_length:\n",
    "            truncated_length = max_length - 3\n",
    "            text = text[:truncated_length] + \"...\"\n",
    "\n",
    "        lines = []\n",
    "        for i in range(0, len(text), max_width):\n",
    "            end_index = i + max_width\n",
    "            segment = text[i:end_index]\n",
    "            lines.append(segment)\n",
    "\n",
    "        result = \"\\n\".join(lines).encode(\"unicode_escape\").decode(\"utf-8\")\n",
    "        return result\n",
    "\n",
    "    def wrap_text_on_spaces_and_underscores(self, text, max_width=25):\n",
    "        if max_width <= 0:\n",
    "            raise ValueError(\"max_width must be a positive integer.\")\n",
    "\n",
    "        words = text.split(\" \")\n",
    "        line = \"\"\n",
    "        lines = []\n",
    "\n",
    "        for word in words:\n",
    "            if len(word) > max_width:\n",
    "                smaller_words = word.split('_')\n",
    "                for smaller_word in smaller_words:\n",
    "                    if len(line) + len(smaller_word) < max_width:\n",
    "                        line += f'_{smaller_word}'\n",
    "                    else:\n",
    "                        start_of_split: bool = smaller_word in smaller_words[0] or smaller_words[0] in line\n",
    "                        lines.append(line if start_of_split else f'_{line}') \n",
    "                        line = smaller_word\n",
    "                \n",
    "            elif len(line) + len(word) < max_width:\n",
    "                line += \" \" + word\n",
    "            else:\n",
    "                lines.append(line)\n",
    "                line = word\n",
    "        lines.append(line)\n",
    "\n",
    "        result = \"\\n\".join(lines).encode(\"unicode_escape\").decode(\"utf-8\")\n",
    "        return result\n",
    "\n",
    "    def add_note_over(self, device, note, color=\"lightgreen\"):\n",
    "        device = self.clean_text(device)\n",
    "        # note = self.wrap_text(note)\n",
    "\n",
    "        self.diagram_code += f\"rnote over {device} #{color}: {note}\\n\"\n",
    "\n",
    "    def add_hexagon_note_over(self, device, note, color=\"lightgrey\"):\n",
    "        device = self.clean_text(device)\n",
    "        # note = self.wrap_text(note)\n",
    "\n",
    "        self.diagram_code += f\"hnote over {device} #{color}: {note}\\n\"\n",
    "\n",
    "    def add_command_call(self, from_device, to_device, note):\n",
    "        from_device = self.clean_text(from_device)\n",
    "        to_device = self.clean_text(to_device)\n",
    "        note = self.wrap_text_on_spaces_and_underscores(note)\n",
    "\n",
    "        self.diagram_code += f\"{from_device} -> {to_device}: {note}\\n\"\n",
    "\n",
    "    def add_command_response(self, from_device, to_device, note):\n",
    "        from_device = self.clean_text(from_device)\n",
    "        to_device = self.clean_text(to_device)\n",
    "        note = self.wrap_text_on_spaces_and_underscores(note)\n",
    "\n",
    "        self.diagram_code += f\"{from_device} --> {to_device}: {note}\\n\"\n",
    "\n",
    "    def add_divider(self, divider_name: str):\n",
    "        self.diagram_code += f'== {divider_name} ==\\n'\n",
    "\n",
    "    def add_new_page(self, page_title: str):\n",
    "        self.diagram_code += f'newpage {page_title}\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log parser class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogParser:\n",
    "    def __init__(self):\n",
    "        self.log_pattern_callbacks: list[tuple[str, callable]] = []\n",
    "\n",
    "    def _parse_log_line(self, log_line):\n",
    "        for pattern, pattern_cb in self.log_pattern_callbacks:\n",
    "            match = re.search(pattern, log_line)\n",
    "            if match:\n",
    "                # prefix|iso_date_string|log_level|runner|action|log_line|device|message\n",
    "                group_values = match.groups()\n",
    "                pattern_cb(*group_values)\n",
    "                break\n",
    "\n",
    "    def parse_file(self, file_path):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            logs = file.readlines()\n",
    "\n",
    "        for log in logs:\n",
    "            self._parse_log_line(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom event and log parser class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventsAndLogsFileParser(LogParser):\n",
    "    def __init__(\n",
    "            self,\n",
    "            device_hierarchy: list=[],\n",
    "            limit_track_load_table_calls: bool=True,\n",
    "            show_events: bool=False,\n",
    "            show_component_state_updates: bool=False,\n",
    "            include_dividers: bool=True,\n",
    "            use_new_pages: bool=False,\n",
    "            group_devices: bool=True,\n",
    "            include_lrc_ids: bool=False,\n",
    "            ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.limit_track_load_table_calls = limit_track_load_table_calls\n",
    "        self.show_events = show_events\n",
    "        self.show_component_state_updates = show_component_state_updates\n",
    "        self.include_dividers = include_dividers\n",
    "        self.use_new_pages = use_new_pages\n",
    "        self.group_devices = group_devices\n",
    "        self.include_lrc_ids = include_lrc_ids\n",
    "\n",
    "        self.sequence_diagram = PlantUMLSequenceDiagram()\n",
    "        self.device_hierarchy = device_hierarchy\n",
    "        self.running_lrc_status_updates = {}\n",
    "\n",
    "        self.log_pattern_callbacks = [\n",
    "            [LOG_REGEX_PATTERN, self.log_callback],\n",
    "            [EVENT_REGEX_PATTERN, self.event_callback],\n",
    "        ]\n",
    "\n",
    "        self.track_load_table_count = 0\n",
    "        self.brand_new_diagram = True\n",
    "\n",
    "    def get_likely_caller_from_hierarchy(self, device) -> str:\n",
    "        for hierarchy_list in self.device_hierarchy:\n",
    "            if device not in hierarchy_list or device == hierarchy_list[0]:\n",
    "                continue\n",
    "            device_index = hierarchy_list.index(device)\n",
    "            hierarchy_index = self.device_hierarchy.index(hierarchy_list)\n",
    "            likely_caller = self.device_hierarchy[hierarchy_index][device_index - 1]\n",
    "            # print(f'Likely caller of device {device} is {likely_caller}')\n",
    "            return likely_caller\n",
    "        print(f\"Setting unknown caller for device {device}\")\n",
    "        return \"unknown\"\n",
    "\n",
    "    def get_method_from_lrc_id(self, lrc_id: str) -> str:\n",
    "        return \"_\".join(lrc_id.split(\"_\")[2:])\n",
    "\n",
    "    def parse(self, file_path: str, output_file_path: str, actor: str=None):\n",
    "        log_file_name = file_path.split(\"/\")[-1]\n",
    "\n",
    "        cleaned_log_file_name = self.sequence_diagram.clean_text(log_file_name)\n",
    "        title = f\"Sequence diagram generated from\\n{cleaned_log_file_name}\".encode(\n",
    "            \"unicode_escape\"\n",
    "        ).decode(\"utf-8\")\n",
    "        \n",
    "        if not actor:\n",
    "            actor = self.device_hierarchy[0][0]\n",
    "\n",
    "        self.actor = actor\n",
    "\n",
    "        self.running_lrc_status_updates = {}\n",
    "        self.sequence_diagram.start_diagram(title, actor)\n",
    "\n",
    "        # Add participants to ensure order of swimlanes\n",
    "        previous_group, previous_colour = self.determine_box_name_and_colour(self.device_hierarchy[0][1])\n",
    "        if self.group_devices:\n",
    "            self.sequence_diagram.add_box(previous_group, previous_colour)\n",
    "\n",
    "        for hierarchy_list in self.device_hierarchy:\n",
    "            for device in hierarchy_list[1:]:\n",
    "                current_group, current_colour = self.determine_box_name_and_colour(device)\n",
    "                if self.group_devices and previous_group != current_group:\n",
    "                    self.sequence_diagram.end_box()\n",
    "                    self.sequence_diagram.add_box(current_group, current_colour)\n",
    "                    previous_group = current_group\n",
    "\n",
    "                self.sequence_diagram.add_participant(device)\n",
    "        \n",
    "        if self.group_devices:\n",
    "            self.sequence_diagram.end_box()\n",
    "\n",
    "        self.parse_file(file_path)\n",
    "\n",
    "        self.sequence_diagram.end_diagram()\n",
    "\n",
    "        # Save the PlantUML diagram code to a file\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(self.sequence_diagram.diagram_code)\n",
    "\n",
    "    def get_cleaned_device_name(self, device: str, info_type: str = 'none') -> str:\n",
    "        if 'full_trl' in info_type:\n",
    "            # tango://tango-databaseds.staging-dish-lmc-ska001.svc.miditf.internal.skao.int:10000/mid-dish/dish-manager/SKA001\n",
    "            device = device.split('/', maxsplit=3)[-1] # only get the trl part of the full name\n",
    "\n",
    "        try:\n",
    "            cleaned_device = device.split('/', maxsplit=1)[1]  # e.g. dish-manager/ska001\n",
    "        except Exception as e:\n",
    "            print(f'Error when cleaning device ({device}): {e}')\n",
    "            return ''\n",
    "            \n",
    "\n",
    "        # mid-csp and mid-sdp are both just called \"subarray\" or \"control\", to differentiate, add the \n",
    "        # first part of the trl. The spfrxpu devices also need the first element to get the dish number\n",
    "        if cleaned_device.startswith('subarray/') \\\n",
    "            or cleaned_device.startswith('spfrxpu/') \\\n",
    "            or cleaned_device.startswith('control/'):\n",
    "            if 'event' in info_type:\n",
    "                # e.g. MidCspSubarray(mid-csp/subarray/01)\n",
    "                trl_start = device.split('(', 1)[1]\n",
    "            elif 'log' in info_type:\n",
    "                # e.g. tango-device:mid-csp/subarray/01\n",
    "                trl_start = device.split('tango-device:', 1)[1]\n",
    "            else:\n",
    "                # e.g. mid-csp/subarray/01 or [ska001/spfrxpu/controller]\n",
    "                trl_start = device.strip('[')\n",
    "\n",
    "            cleaned_device = f'{trl_start.split(\"/\")[0]}/{cleaned_device}'\n",
    "\n",
    "        # Remove last character if it's an event because the closing parenthesis will still be there\n",
    "        cleaned_device = cleaned_device[:-1] if info_type == 'event' or device.startswith('[') else cleaned_device\n",
    "\n",
    "        # Replace / with . and for plantUML\n",
    "        cleaned_device = cleaned_device.replace('/', '.')\n",
    "\n",
    "        return cleaned_device.lower()\n",
    "\n",
    "    def determine_box_name_and_colour(self, device: str) -> tuple[str, str]:\n",
    "        '''Determine the group the device falls under and assign the appropriate colour'''\n",
    "        match device:\n",
    "            case _ if device.startswith('tm'):\n",
    "                return DeviceGroup.TMC.value\n",
    "            case _ if device.startswith(('mid-csp', 'mid_csp', 'sub_elt')):\n",
    "                return DeviceGroup.CSP.value\n",
    "            case _ if device.startswith('mid-sdp'):\n",
    "                return DeviceGroup.SDP.value\n",
    "            case _ if device.startswith(('dish-', 'ds-', 'ska', 'simulator_spfc')):\n",
    "                return DeviceGroup.DISHES.value\n",
    "            case _:\n",
    "                print(f'Device {device} set to UNKNOWN group')\n",
    "                return DeviceGroup.UNKNOWN.value\n",
    "\n",
    "    def log_callback(self, prefix: str, iso_date_string: str, log_level: str,\n",
    "                     runner: str, action: str, log_line: str, device: str, message: str):\n",
    "        # Ignore empty devices        \n",
    "        if device == \"\":\n",
    "            return\n",
    "        \n",
    "        # Example log message:\n",
    "        # 1724676115.079 -  Log  - 1|2024-08-26T12:41:55.079Z|DEBUG|Thread-9 (_event_consumer)|\n",
    "        # _component_state_changed|dish_manager_cm.py#390|tango-device:mid-dish/dish-manager/SKA001|...\n",
    "        cleaned_device = self.get_cleaned_device_name(device, 'log')\n",
    "\n",
    "        if action in ['update_long_running_command_result', 'update_command_result']:\n",
    "            # <prefix>|<date>|INFO|longRunningCommandResult|update_long_running_command_result|<log_line>|\n",
    "            # tango-device:ska_mid/tm_subarray_node/1|Received longRunningCommandResult event for device:\n",
    "            #  ska_mid/tm_leaf_node/sdp_subarray01, with value: ('1731055110.2204533_15076717473253_On', '[0, \"Command Completed\"]')\n",
    "            self.handle_lrc_result_log(cleaned_device, message)\n",
    "\n",
    "        elif action in ['invoke_command', 'execute_command']:\n",
    "            # <prefix>|<date>|DEBUG|<runner>|invoke_command|<log_line>|tango-device:ska_mid/tm_central/central_node|\n",
    "            # Invoked On on device ska_mid/tm_subarray_node/2\n",
    "            self.handle_invoke_or_execute_command_log(cleaned_device, message)\n",
    "\n",
    "        elif action == '_debug_patch':\n",
    "            # <prefix>|<date>|DEBUG|<runner|_debug_patch|<log_line>|tango-device:ska_mid/tm_central/central_node|\n",
    "            # -> CentralNodeMid.TelescopeOn()\n",
    "            self.handle_debug_patch_log(cleaned_device, message)\n",
    "\n",
    "        elif action == '_set_k_numbers_to_dish':\n",
    "            # <prefix>|<date>|INFO|<runner>|_set_k_numbers_to_dish|<log_line>|\n",
    "            # tango-device:ska_mid/tm_central/central_node|Invoking SetKValue on dish adapter ska_mid/tm_leaf_node/d0001\n",
    "            self.handle_set_k_numbers_to_dish_log(cleaned_device, message)\n",
    "        \n",
    "        elif action in ['turn_on_csp', 'turn_on_sdp', 'turn_off_csp', 'turn_off_sdp']:\n",
    "            # <prefix>|<date>|INFO|<runner>|turn_on_csp|<log_line>|tango-device:ska_mid/tm_central/central_node|\n",
    "            # Invoking On command for ska_mid/tm_leaf_node/csp_master devices\n",
    "            self.handle_csp_sdp_invoking_on_off_command_log(cleaned_device, message)\n",
    "\n",
    "        elif action in [\n",
    "            'do_mid',\n",
    "            'call_adapter_method', \n",
    "            'assign_csp_resources',\n",
    "            'scan_dishes',\n",
    "        ]:\n",
    "            # <prefix>|<date>|INFO|<runner>|assign_csp_resources|<log_line>|\n",
    "            # tango-device:ska_mid/tm_subarray_node/1|AssignResources command invoked on ska_mid/tm_leaf_node/csp_subarray01\n",
    "            # <prefix>|<date>|INFO|<runner>|do_mid|<log_line>|tango-device:ska_mid/tm_leaf_node/csp_subarray01|\n",
    "            # Invoking AssignResources command on mid-csp/subarray/01\n",
    "            self.handle_invoking_most_commands_log(cleaned_device, message)\n",
    "\n",
    "        elif action in ['release_csp_resources', 'release_sdp_resources']:\n",
    "            # These guys wanted to be special for release resources\n",
    "            # <prefix>|<date>|INFO|<runner>|release_sdp_resources|<log_line>|tango-device:ska_mid/tm_subarray_node/1|\n",
    "            # ReleaseAllResources command invoked on SDP Subarray Leaf Node  ska_mid/tm_leaf_node/sdp_subarray01\n",
    "            self.handle_csp_sdp_release_resources_command_log(cleaned_device, message)\n",
    "\n",
    "        elif action == \"_info_patch\":\n",
    "            self.info_patch_cb(\n",
    "                prefix, iso_date_string, log_level, runner, action, log_line, cleaned_device, message\n",
    "            )\n",
    "        elif action == \"_update_component_state\" and self.show_component_state_updates:\n",
    "            self.component_state_update_cb(\n",
    "                prefix, iso_date_string, log_level, runner, action, log_line, cleaned_device, message\n",
    "            )\n",
    "\n",
    "    ## HELPER METHODS FOR LOG MATCHING ##\n",
    "    def handle_lrc_result_log(self, cleaned_device: str, message: str):\n",
    "        '''Handles parsing of longRunningCommandResult logs and updates the sequence diagram'''\n",
    "        match = LOG_LRC_RESULT_REGEX_PATTERN.search(message)\n",
    "        if match:\n",
    "            from_device = match.group(1).strip()\n",
    "            command_id = match.group(2).strip()\n",
    "            status = match.group(3).strip()\n",
    "\n",
    "            # Ignore staging statuses for cleaner diagrams\n",
    "            if status.lower() == 'staging':\n",
    "                return\n",
    "\n",
    "            # Remove ID from command \n",
    "            # 1731336386.5340867_71131397947360_LoadDishCfg to LoadDishCfg\n",
    "            command = command_id.split('_')[-1]\n",
    "\n",
    "            # Clean the target device name for PlantUML\n",
    "            cleaned_from_device = self.get_cleaned_device_name(from_device)\n",
    "\n",
    "            # Add an arrow to the sequence diagram\n",
    "            self.sequence_diagram.add_command_response(\n",
    "                cleaned_from_device, cleaned_device, f'\"\"{command}\"\" -> {status}'\n",
    "            )\n",
    "\n",
    "    def handle_invoke_or_execute_command_log(self, cleaned_device: str, message: str):\n",
    "        '''Handles parsing of invoke_command and execute_command logs and updates the sequence diagram'''\n",
    "        match = INVOKE_EXECUTE_COMMAND_REGEX_PATTERN.search(message)\n",
    "        if match:\n",
    "            command_name = match.group(1).strip()\n",
    "\n",
    "            # Exclude spammy commands from the diagram\n",
    "            if command_name in ['MonitorPing', 'TrackLoadTable']:\n",
    "                return\n",
    "            \n",
    "            self.generic_command_match_handling(match, cleaned_device)\n",
    "\n",
    "    def handle_debug_patch_log(self, cleaned_device: str, message: str):\n",
    "        '''Handles parsing of _debug_patch logs and updates the sequence diagram'''\n",
    "        match = DEBUG_PATCH_FORWARD_REGEX_PATTERN.search(message)\n",
    "        if match:\n",
    "            target_class = match.group(1)\n",
    "            command_name = match.group(2)\n",
    "\n",
    "            # Use the device hierarchy to get the likely caller\n",
    "            likely_caller = self.get_likely_caller_from_hierarchy(cleaned_device)\n",
    "\n",
    "            # Most of these logs are directly called from the notebook\n",
    "            # Small trick for setting the notebook as the caller for all mid subarray calls\n",
    "            if target_class == 'SubarrayNodeMid':\n",
    "                likely_caller = self.get_likely_caller_from_hierarchy(likely_caller)\n",
    "\n",
    "            # Use new pages for major notebook commands to split the images\n",
    "            if self.use_new_pages and likely_caller == self.actor:\n",
    "                # We don't want a new page on the very first command\n",
    "                if not self.brand_new_diagram:\n",
    "                    self.sequence_diagram.add_new_page(command_name)\n",
    "                \n",
    "                self.brand_new_diagram = False\n",
    "\n",
    "            # Create a divider if a new notebook command was run\n",
    "            if self.include_dividers and likely_caller == self.actor:\n",
    "                self.sequence_diagram.add_divider(command_name)\n",
    "\n",
    "\n",
    "            # Add an arrow to the sequence diagram from the likely caller to the target device\n",
    "            self.sequence_diagram.add_command_call(\n",
    "                likely_caller, cleaned_device, f'\"\"{target_class}.{command_name}\"\"'\n",
    "            )\n",
    "\n",
    "    def handle_set_k_numbers_to_dish_log(self, cleaned_device: str, message: str):\n",
    "        '''Handles parsing of _set_k_numbers_to_dish logs and updates the sequence diagram'''\n",
    "        match = K_VALUES_TO_DISH_REGEX_PATTERN.search(message)\n",
    "        if match:\n",
    "            self.generic_command_match_handling(match, cleaned_device)\n",
    "\n",
    "    def handle_csp_sdp_invoking_on_off_command_log(self, cleaned_device: str, message: str):\n",
    "        '''Handles parsing turn_on_csp and turn_on_sdp logs and updates the sequence diagram'''\n",
    "        # this is not \"On\" or \"Off\" for the master device, but to get them to turn on/off the lower devices\n",
    "        # Adjusting the text of the command going to the sequence diagram for clarity\n",
    "        adjustment = 'for lower devices command'\n",
    "        message = message.replace('command', adjustment)\n",
    "\n",
    "        match = CSP_SDP_ON_OFF_COMMAND_REGEX_PATTERN.search(message)\n",
    "        if match:\n",
    "            self.generic_command_match_handling(match, cleaned_device)\n",
    "\n",
    "    def handle_invoking_most_commands_log(self, cleaned_device: str, message: str):\n",
    "        '''Handles parsing do_mid, call_adapter_method, assign_csp_resources and scan_dishes logs; \n",
    "        and updates the sequence diagram'''\n",
    "        # There is one log that just says \"... on SubarrayNode.\"\n",
    "        non_standard_subarray_device_in_log = 'SubarrayNode.'   # these have full stops\n",
    "        standardised_subarray_device = 'ska_mid/tm_subarray_node/1'\n",
    "\n",
    "        if message.endswith(non_standard_subarray_device_in_log):\n",
    "            message = message.replace(non_standard_subarray_device_in_log, standardised_subarray_device)\n",
    "\n",
    "        # Some of these logs end with a full stop which then gets included in the device name\n",
    "        if message.endswith('.'):\n",
    "            message = message[:-1]\n",
    "\n",
    "        match = INVOKING_COMMAND_REGEX_PATTERN.search(message)\n",
    "        if match:\n",
    "            # Some of the call_adapter_method have the full tango trl in the device name\n",
    "            if match.group(2).startswith('tango:'):\n",
    "                self.generic_command_match_handling(match, cleaned_device, 'full_trl')\n",
    "            else:\n",
    "                self.generic_command_match_handling(match, cleaned_device)\n",
    "            return\n",
    "\n",
    "        match = COMMAND_INVOKED_REGEX_PATTERN.search(message)\n",
    "        if match:\n",
    "            self.generic_command_match_handling(match, cleaned_device)\n",
    "\n",
    "    def handle_csp_sdp_release_resources_command_log(self, cleaned_device: str, message: str):\n",
    "        '''Handles release_csp_resources and release_sdp_resources logs and updates the sequence diagram'''\n",
    "        match = CSP_SDP_RELEASE_RESOURCES_COMMAND_REGEX_PATTERN.search(message)\n",
    "        if match:\n",
    "            self.generic_command_match_handling(match, cleaned_device)\n",
    "\n",
    "    def info_patch_cb(self, prefix, iso_date_string, log_level, runner,\n",
    "                      action, log_line, device, message):\n",
    "        if \"->\" in message:\n",
    "            match = INCOMING_COMMAND_CALL_REGEX_PATTERN.search(message)\n",
    "            if match:\n",
    "                method = match.group(1)\n",
    "                method = method.split(\".\")[1]\n",
    "\n",
    "                # Reduce \"TrackLoadTable\" commands from the diagram\n",
    "                if method == \"TrackLoadTable\":\n",
    "                    self.track_load_table_count += 1\n",
    "                    if self.limit_track_load_table_calls and \\\n",
    "                       self.track_load_table_count > TRACK_LOAD_TABLE_LIMIT:\n",
    "                        return\n",
    "\n",
    "                caller = self.get_likely_caller_from_hierarchy(device)\n",
    "                self.sequence_diagram.add_command_call(caller, device, f'\"\"{method}\"\"')\n",
    "\n",
    "        elif \"<-\" in message:\n",
    "            match = RETURN_COMMAND_CALL_REGEX_PATTERN.search(message)\n",
    "            if match:\n",
    "                return_val = match.group(1)\n",
    "                method = match.group(2)\n",
    "                method = method.split(\".\")[1]\n",
    "\n",
    "                # Reduce \"TrackLoadTable\" commands from the diagram\n",
    "                if method == 'TrackLoadTable':\n",
    "                    self.track_load_table_count += 1\n",
    "                    if self.limit_track_load_table_calls and \\\n",
    "                       self.track_load_table_count > TRACK_LOAD_TABLE_LIMIT:\n",
    "                        return\n",
    "                    \n",
    "                # The ResultCode.QUEUED logs seem to be delayed and duplicated so exclude them\n",
    "                if 'ResultCode.QUEUED' in return_val:\n",
    "                    return\n",
    "\n",
    "                caller = self.get_likely_caller_from_hierarchy(device)\n",
    "\n",
    "                self.sequence_diagram.add_command_response(\n",
    "                    device, caller, f'\"\"{method}\"\" -> {return_val}'\n",
    "                )\n",
    "\n",
    "    def component_state_update_cb(self, prefix, iso_date_string, log_level,\n",
    "                                  runner, action, log_line, device, message):\n",
    "        search_string = r\"Updating (\\w*) (\\w*) component state with \\[(.*)\\]\"\n",
    "\n",
    "        match = re.search(search_string, message)\n",
    "\n",
    "        if match:\n",
    "            string_dict = match.group(3)\n",
    "            string_dict = string_dict.replace(\"<\", \"'<\")\n",
    "            string_dict = string_dict.replace(\">\", \">'\")\n",
    "            component_state_updates = ast.literal_eval(string_dict)\n",
    "\n",
    "            note_text = \"Component state update\"\n",
    "            for attr, attr_value in component_state_updates.items():\n",
    "                note_text += f'\\n\"\"{attr} = {attr_value}\"\"'.encode(\"unicode_escape\").decode(\n",
    "                    \"utf-8\"\n",
    "                )\n",
    "            self.sequence_diagram.add_hexagon_note_over(device, note_text)\n",
    "\n",
    "    def generic_command_match_handling(self, match: Match[str], cleaned_device: str, target_device_type: str='none'):\n",
    "        '''Handle a generic command with target device and add it to the sequence diagram'''\n",
    "        command_name = match.group(1).strip()\n",
    "        target_device = match.group(2).strip()\n",
    "\n",
    "        # Clean the target device name for PlantUML\n",
    "        cleaned_target_device = self.get_cleaned_device_name(target_device, target_device_type)\n",
    "\n",
    "        # Add an arrow to the sequence diagram\n",
    "        self.sequence_diagram.add_command_call(\n",
    "            cleaned_device, cleaned_target_device, f'\"\"{command_name}\"\"'\n",
    "        )\n",
    "\n",
    "    def event_callback(self, prefix, device: str, event_attr, val):\n",
    "        # Ignore empty devices        \n",
    "        if device == \"\":\n",
    "            return\n",
    "\n",
    "        # Example event messages:\n",
    "        # 1724660914.761 - Event - 2024-08-26 08:28:34.761448\tDishManager(mid-dish/dish-manager/ska001)\n",
    "        # \tlongrunningcommandstatus\t('1724660914.663982_241979260268973_SetStowMode', 'COMPLETED')\n",
    "        # 1724660914.761 - Event - 2024-09-18 08:44:43.859312\tMidCspSubarray(mid-csp/subarray/01)\n",
    "        #   longrunningcommandstatus\t('1726641882.6817706_174896405886953_AssignResources', 'STAGING')\n",
    "        cleaned_device = self.get_cleaned_device_name(device, \"event\")\n",
    "        caller = self.get_likely_caller_from_hierarchy(cleaned_device)\n",
    "\n",
    "        if \"longrunningcommand\" in event_attr:\n",
    "            self.handle_lrc_event_log(cleaned_device, caller, event_attr, val)\n",
    "        elif self.show_events:\n",
    "            self.sequence_diagram.add_note_over(\n",
    "                cleaned_device,\n",
    "                f'Event\\n\"\"{event_attr} = {val.strip()}\"\"'.encode(\"unicode_escape\").decode(\n",
    "                    \"utf-8\"\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def handle_lrc_event_log(self, device, caller, event_attr, val):\n",
    "        if \"longrunningcommandstatus\" in event_attr:\n",
    "            lrc_statuses = LRC_TUPLE_REGEX_PATTERN.findall(val)\n",
    "            for index, (lrc_id, status) in enumerate(lrc_statuses):\n",
    "                # If there are any newer updates for this lrc in the LRC statuses then skip this\n",
    "                newer_status_found = False\n",
    "                if index + 1 < len(lrc_statuses):\n",
    "                    for i in range(index + 1, len(lrc_statuses)):\n",
    "                        if lrc_statuses[i][0] == lrc_id:\n",
    "                            newer_status_found = True\n",
    "                            break\n",
    "\n",
    "                if newer_status_found:\n",
    "                    break\n",
    "\n",
    "                method_name = self.get_method_from_lrc_id(lrc_id)\n",
    "\n",
    "                if status == \"STAGING\":\n",
    "                    # Only track methods which are called in the scope of the file\n",
    "                    # This avoids some noise left over in LRC attributes from previous test / setup\n",
    "                    self.running_lrc_status_updates[lrc_id] = []\n",
    "\n",
    "                # Only update if its a method called in the scope of this file and its a new status\n",
    "                if (\n",
    "                    lrc_id in self.running_lrc_status_updates\n",
    "                    and status not in self.running_lrc_status_updates[lrc_id]\n",
    "                    and status != \"STAGING\"\n",
    "                ):\n",
    "                    self.running_lrc_status_updates[lrc_id].append(status)\n",
    "                    self.sequence_diagram.add_command_response(\n",
    "                        device, caller, f'\"\"{lrc_id if self.include_lrc_ids else method_name}\"\" -> {status}'\n",
    "                    )\n",
    "        elif \"longrunningcommandprogress\" in event_attr:\n",
    "            lrc_progresses = LRC_TUPLE_REGEX_PATTERN.findall(val)\n",
    "            for lrc_id, progress in lrc_progresses:\n",
    "                # Only show progress updates for methods which have been staged\n",
    "                if lrc_id in self.running_lrc_status_updates:\n",
    "                    method_name = self.get_method_from_lrc_id(lrc_id)\n",
    "                    self.sequence_diagram.add_command_call(\n",
    "                        device, device, f'\"\"{lrc_id if self.include_lrc_ids else method_name}\"\" -> {progress}'\n",
    "                    )\n",
    "        elif event_attr == \"longrunningcommandresult\":\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup tracked devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrackedDevice:\n",
    "    \"\"\"Class to group tracked device information\"\"\"\n",
    "\n",
    "    device_proxy: tango.DeviceProxy\n",
    "    attribute_names: Tuple[str]\n",
    "    subscription_ids: List[int] = field(default_factory=list)\n",
    "\n",
    "\n",
    "tracked_devices = [\n",
    "    TrackedDevice(\n",
    "        tango.DeviceProxy(device_trl),\n",
    "        (\n",
    "            \"longrunningcommandstatus\",\n",
    "            \"longrunningcommandresult\",\n",
    "            \"longrunningcommandprogress\",\n",
    "        ),\n",
    "    )\n",
    "    for device_trl in tracked_device_trls\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event printer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventPrinter:\n",
    "    \"\"\"Class that writes attribute changes to a file\"\"\"\n",
    "\n",
    "    def __init__(self, filename: str, tracked_devices: Tuple[TrackedDevice] = ()) -> None:\n",
    "        self.tracked_devices = tracked_devices\n",
    "        self.filename = filename\n",
    "        self.events = []\n",
    "\n",
    "    def __enter__(self):\n",
    "        for tracked_device in self.tracked_devices:\n",
    "            dp = tracked_device.device_proxy\n",
    "            for attr_name in tracked_device.attribute_names:\n",
    "                sub_id = dp.subscribe_event(attr_name, tango.EventType.CHANGE_EVENT, self)\n",
    "                tracked_device.subscription_ids.append(sub_id)\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, exc_tb):\n",
    "        for tracked_device in self.tracked_devices:\n",
    "            try:\n",
    "                dp = tracked_device.device_proxy\n",
    "                for sub_id in tracked_device.subscription_ids:\n",
    "                    dp.unsubscribe_event(sub_id)\n",
    "            except tango.DevError:\n",
    "                pass\n",
    "\n",
    "    def add_event(self, timestamp, message):\n",
    "        self.events.append((timestamp, message))\n",
    "        with open(self.filename, \"a\") as open_file:\n",
    "            open_file.write(\"\\n\" + message)\n",
    "\n",
    "    def push_event(self, ev: tango.EventData):\n",
    "        event_string = \"\"\n",
    "        if ev.err:\n",
    "            err = ev.errors[0]\n",
    "            event_string = f\"\\nEvent Error {err.desc} {err.origin} {err.reason}\"\n",
    "        else:\n",
    "            attr_name = ev.attr_name.split(\"/\")[-1]\n",
    "            attr_value = ev.attr_value.value\n",
    "            if ev.attr_value.type == tango.CmdArgType.DevEnum:\n",
    "                attr_value = ev.device.get_attribute_config(attr_name).enum_labels[attr_value]\n",
    "\n",
    "            event_string = f\"Event - {ev.reception_date}\\t{ev.device}\\t{attr_name}\\t{attr_value}\"\n",
    "\n",
    "        self.add_event(ev.reception_date.totime(), event_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the event printer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TZ\"] = \"Africa/Johannesburg\"\n",
    "\n",
    "# Get the current datetime\n",
    "datetime_start = datetime.now(timezone.utc) \n",
    "iso_start = datetime_start.isoformat()\n",
    "\n",
    "date = datetime_start.strftime(\"%Y%m%d\")\n",
    "time_start = datetime_start.strftime(\"%H%M%S\")\n",
    "events_file_name = f\"generated_events-{date}-{time_start}.txt\"\n",
    "event_printer = EventPrinter(\n",
    "    events_file_name, tracked_devices\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the event printer monitoring before running commands on your monitored device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_printer.__enter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exit the printer to unsubscribe from attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_printer.__exit__(None, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to retrieve logs from pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pod_logs = {}\n",
    "\n",
    "def get_iso_date_string_from_string(val: str):\n",
    "    # Log example: 1|2024-11-08T08:38:30.211Z|INFO|...\n",
    "    match = re.search(ISO_DATE_STRING_PATTERN, val)\n",
    "    return match.group() if match else \"\"\n",
    "\n",
    "def get_pod_logs_and_timestamps(namespace, pod_name, since_time):\n",
    "    command = f\"kubectl logs {pod_name} -n {namespace} --since-time={since_time}\"\n",
    "    # print(command)\n",
    "\n",
    "    try:\n",
    "        # Run the command and capture the output\n",
    "        result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        \n",
    "        api_response = result.stdout  # Capture standard output\n",
    "\n",
    "        # Check if there is any error output (0 is success)\n",
    "        if result.returncode != 0:\n",
    "            print(f\"Error for {pod_name}: {result.stderr}\")\n",
    "            return []\n",
    "        \n",
    "        # Make sure api_response is not empty\n",
    "        if not api_response:\n",
    "            print(f\"No logs found for {pod_name}.\")\n",
    "            return []\n",
    "        \n",
    "        # Save logs to files for debugging\n",
    "        # with open(f'{pod_name}-{date}-{time_start}.txt', 'w', encoding='utf-8') as f:\n",
    "        #     f.write(api_response)\n",
    "\n",
    "        logs = api_response.splitlines()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while running the command for {pod_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Extract times from each line in the logs (e.g. 2024-08-26T07:16:11.051Z)\n",
    "    extracted_logs = []\n",
    "    for log in logs:\n",
    "        # Remove null characters from the line\n",
    "        log = log.replace(\"\\x00\", \"\").strip()\n",
    "        # Skip empty logs\n",
    "        if log == \"\":\n",
    "            continue\n",
    "        \n",
    "        # Search for the timestamp in each log entry\n",
    "        iso_date_string = get_iso_date_string_from_string(log)\n",
    "        if iso_date_string:\n",
    "            try:\n",
    "                # Parse the timestamp and add it to the extracted logs\n",
    "                time_obj = datetime.strptime(iso_date_string, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "                adjusted_timestamp = time_obj.timestamp()\n",
    "                if '|DEBUG|' in log:\n",
    "                    adjusted_timestamp -= DEBUG_LOG_TIME_ADJUSTMENT_SECONDS\n",
    "                else:\n",
    "                    adjusted_timestamp -= GENERAL_LOG_TIME_ADJUSTMENT_SECONDS\n",
    "\n",
    "                extracted_logs.append((adjusted_timestamp, f\" Log  - {log}\"))\n",
    "            except ValueError as e:\n",
    "                print(f\"Timestamp parsing error for log: {log} - {e}\")\n",
    "        else:\n",
    "            # print(f\"No timestamp found in log: {log}\")\n",
    "            continue\n",
    "\n",
    "    return extracted_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_and_logs_file_name = f\"events_and_logs-{date}-{time_start}.txt\"\n",
    "sequence_diagram_file_name = f\"sequence-diagram-{date}-{time_start}.puml\"\n",
    "\n",
    "# Loop over each namespace and its pods\n",
    "# * Note: This takes a handful of seconds\n",
    "for namespace, pods in namespaces_pods.items():\n",
    "    for pod in pods:\n",
    "        all_pod_logs[pod] = get_pod_logs_and_timestamps(namespace, pod, iso_start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine events and logs into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and sort logs/events\n",
    "captured_events = event_printer.events\n",
    "combined_events_and_logs = []\n",
    "\n",
    "for logs in all_pod_logs.values():\n",
    "    combined_events_and_logs.extend(logs)\n",
    "\n",
    "combined_events_and_logs.extend(captured_events)\n",
    "\n",
    "combined_events_and_logs.sort(key=lambda x: x[0])\n",
    "\n",
    "# print(combined_events_and_logs)\n",
    "\n",
    "# Write the combined entries to the output file\n",
    "with open(events_and_logs_file_name, \"w\") as file:\n",
    "    for timestamp, message in combined_events_and_logs:\n",
    "        file.write(f\"{timestamp:.3f} - {message}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the events and logs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message before: Invoking On command for ska_mid/tm_leaf_node/csp_master devices\n",
      "Message after: Invoking On for lower devices command for ska_mid/tm_leaf_node/csp_master devices\n",
      "On for lower devices\n",
      "ska_mid/tm_leaf_node/csp_master\n",
      "Message before: Invoking On command for ska_mid/tm_leaf_node/sdp_master devices\n",
      "Message after: Invoking On for lower devices command for ska_mid/tm_leaf_node/sdp_master devices\n",
      "On for lower devices\n",
      "ska_mid/tm_leaf_node/sdp_master\n",
      "Message before: Invoking Off command for ska_mid/tm_leaf_node/csp_master devices\n",
      "Message after: Invoking Off for lower devices command for ska_mid/tm_leaf_node/csp_master devices\n",
      "Off for lower devices\n",
      "ska_mid/tm_leaf_node/csp_master\n",
      "Message before: Invoking Off command for ska_mid/tm_leaf_node/sdp_master devices\n",
      "Message after: Invoking Off for lower devices command for ska_mid/tm_leaf_node/sdp_master devices\n",
      "Off for lower devices\n",
      "ska_mid/tm_leaf_node/sdp_master\n"
     ]
    }
   ],
   "source": [
    "# To generate a more verbose diagram with events and component state updates,\n",
    "# set first two arguments to True\n",
    "file_parser = EventsAndLogsFileParser(\n",
    "    device_hierarchy=device_hierarchy,\n",
    "    limit_track_load_table_calls=True,\n",
    "    show_events=False,\n",
    "    show_component_state_updates=False,\n",
    "    include_dividers=True,\n",
    "    use_new_pages=True,\n",
    "    group_devices=True,\n",
    "    include_lrc_ids=True,\n",
    ")\n",
    "\n",
    "events_and_logs_file_path = f\"./{events_and_logs_file_name}\"\n",
    "\n",
    "file_parser.parse(\n",
    "    events_and_logs_file_path, sequence_diagram_file_name\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
