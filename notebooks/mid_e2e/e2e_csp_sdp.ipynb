{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Auto Correlation with Talon Deployer and BITE\n",
    "###### Last Updated: 12/04/24\n",
    "\n",
    "This demo will show the basic operation of auto correlation using both the original docker-based Deployer and BITE commands, as well as the new TANGO device based ones. With this notebook, all TANGO commands and attribute changes are made via a [TANGO DeviceProxy](https://pytango.readthedocs.io/en/stable/client_api/device_proxy.html) but the overall steps should be the same for using the JIVE interface or Taranta web interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First, this notebook expects a running environment launched from a pipeline, in particular it assumes one launched from the [SKA-mid-psi](https://gitlab.com/ska-telescope/ska-mid-psi) pipeline. Secondly, for ease of dev work, it also assumes it is run in a virtual env. This notebook was made with Python 3.10 in mind.\n",
    "\n",
    "Finally, make sure all requirements are installed via [poetry](https://python-poetry.org/docs/basic-usage/#installing-dependencies), and after that, grab the imports required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "\n",
    "from astropy.time import Time\n",
    "\n",
    "sys.path.append(\"../../src\")\n",
    "from tango import Database, DevFailed, DeviceProxy\n",
    "\n",
    "import notebook_tools.wait_for_tango as wait_for_tango"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Running on PSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To run on PSI, once running the launch step from the PSI pipeline, grab the booted namespace's name. Also run a check on the ns as well to make sure the pods are ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get ns | grep ska-mid-psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl -n ci-ska-mid-psi-1280777666-jaredmda get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Loading in Variables/Checking Taranta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, set the variables we'll need for the run. First the constants that should not need to be changed unless debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --Requried Vars--\n",
    "# Non-SPD namespace\n",
    "ns = \"\"\n",
    "# The board to be used for the test.\n",
    "target_talon = 0\n",
    "# Set to 0 if to run on actual hardware, 1 to simulate\n",
    "sim_mode = 0\n",
    "\n",
    "# --Optional vars--\n",
    "# Change these values if to specify a certain slim directory for files\n",
    "slim_fs_config = \"\"\n",
    "slim_vis_config = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAC address for the boards.\n",
    "TARGET_MAC_ADDRESS = \"08:c0:eb:9d:47:78\"\n",
    "# Parent directory to use to grab config files.\n",
    "DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), \"data\")\n",
    "# Config file directories\n",
    "COMMON_CONFIGS = os.path.join(DATA_DIR, \"mid_telescope/cbf\")\n",
    "CSP_CONFIGS = os.path.join(DATA_DIR, \"mid_telescope/csp\")\n",
    "TMC_CONFIGS = os.path.join(DATA_DIR, \"mid_telescope/tmc\")\n",
    "HW_CONFIGS = os.path.join(COMMON_CONFIGS, \"hw_config\")\n",
    "# For mapping the talon boards to receptor\n",
    "RECEPTOR_MAP = [\"SKA001\", \"SKA036\", \"SKA063\", \"SKA100\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these set, check the taranta dash to monitor the boards as the rest of the notebook is run through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://142.73.34.170/\" + ns + \"/taranta/dashboard?id=65e7b6f7b72ec70018cdb16a&mode=run\"\n",
    "print(\n",
    "    \"Monitor board status using: https://142.73.34.170/{}/taranta/dashboard?id=65e7b6f7b72ec70018cdb16a&mode=run\".format(\n",
    "        ns\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, all components should be in the `disabled` state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, to set up the target board that that will be used for the auto correlation. While this can be multiple boards, for now only one is needed. Punch out the board(s) and set the `target_talon` to assign it to be used in future steps.\n",
    "\n",
    "The `TANGO_HOST` will be created based of the namespace set earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TANGO_HOST = \"databaseds-tango-base.\" + ns + \".svc.cluster.local:10000\"\n",
    "print(\"Will be using HOST: \", TANGO_HOST)\n",
    "os.environ[\"TANGO_HOST\"] = TANGO_HOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load in the locations of local JSON files for configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting files...\")\n",
    "\n",
    "INIT_SYS_PARAM_FILE = os.path.join(COMMON_CONFIGS, \"sys_params/initial_system_param.json\")\n",
    "ASSIGN_RESOURCES_FILE = os.path.join(TMC_CONFIGS, \"assign_resources.json\")\n",
    "ASSIGN_CSP_RESOURCES_FILE = os.path.join(CSP_CONFIGS, \"assign_resources.json\")\n",
    "CONFIGURE_SCAN_FILE = os.path.join(TMC_CONFIGS, \"configure_scan.json\")\n",
    "SCAN_FILE = os.path.join(TMC_CONFIGS, \"scan.json\")\n",
    "CSP_DELAY_MODEL_FILE = os.path.join(TMC_CONFIGS, \"delay_model.json\")\n",
    "\n",
    "files = [\n",
    "    INIT_SYS_PARAM_FILE,\n",
    "    ASSIGN_RESOURCES_FILE,\n",
    "    ASSIGN_CSP_RESOURCES_FILE,\n",
    "    CONFIGURE_SCAN_FILE,\n",
    "    SCAN_FILE,\n",
    "    CSP_DELAY_MODEL_FILE,\n",
    "]\n",
    "print(\"Checking to make sure files exist...\")\n",
    "for file in files:\n",
    "    if os.path.isfile(file):\n",
    "        print(f\"{file} exists: âœ”ï¸\")\n",
    "    else:\n",
    "        print(f\"{file} does not exist âŒ\")\n",
    "\n",
    "\n",
    "print(\"Checking done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, pass in the SLIM mesh config files by copying them to the namespace, these files should be in the json_files storage folder. Custom files here are not required, but if needed, the following two code blocks can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if slim_fs_config != \"\":\n",
    "    !\"kubectl cp {fs_config_path} {ns}/ds-cbfcontroller-controller-0:/app/mnt/slim/fs_slim_config.yaml\"\n",
    "    print(\"Loaded custom SLIM fs config.\")\n",
    "else:\n",
    "    print(\"SLIM will use default fs config\")\n",
    "if slim_vis_config != \"\":\n",
    "    !\"kubectl cp {vis_config_path} {ns}/ds-cbfcontroller-controller-0:/app/mnt/slim/vis_slim_config.yaml\"\n",
    "    print(\"Loaded custom SLIM vis config.\")\n",
    "else:\n",
    "    print(\"SLIM will use default vis config.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo notebook will interact with the TANGO devices via a device proxy, which will allow us to pass commands into them like the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the device proxies targeting bite and deployer\n",
    "db = Database()\n",
    "deployer = DeviceProxy(\"mid_csp_cbf/ec/deployer\")\n",
    "# Check the devices initially deployed to the database\n",
    "print(\"Check to ensure database contains expected devices.\")\n",
    "print(*db.get_device_exported(\"*\").value_string, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next load in the hardware configuration depending on the talon boards selected. If a higher number board is chosen, need to use the swapped config file, and then modify the board value to match the swap file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_talon > 4:\n",
    "    print(\"Using swap for higher number talons\")\n",
    "    config = \"hw_config_swap_psi.yaml\"\n",
    "    print(\"Modifying target to use lower nums to match swap file\")\n",
    "    target_talon = target_talon - 4\n",
    "else:\n",
    "    print(\"Using standard HW config\")\n",
    "    config = \"hw_config_psi.yaml\"\n",
    "\n",
    "HW_CONFIG_FILE = os.path.join(HW_CONFIGS, config)\n",
    "if os.path.isfile(HW_CONFIG_FILE):\n",
    "    print(\"HW config: âœ”ï¸\")\n",
    "else:\n",
    "    print(\"hw config: âŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now copy this file into the controller pod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl cp $HW_CONFIG_FILE $ns/ds-cbfcontroller-controller-0:/app/mnt/hw_config/hw_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Deploying Devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For deploying the required Tango Devices, there are two options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Deploying Using the Command Line (Old Method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the old method for running the deployer commands, use kubectl's exec function to run commands on the relevant pod, using the deployer script and passing the relevant commands to it as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Deploying to Talon board -> {}\".format(target_talon))\n",
    "!kubectl exec -ti -n $ns ec-deployer -- python3 midcbf_deployer.py --generate-talondx-config --boards=$target_talon\n",
    "!kubectl exec -ti -n $ns ec-deployer -- python3 midcbf_deployer.py --download-artifacts\n",
    "!kubectl exec -ti -n $ns ec-deployer -- python3 midcbf_deployer.py --config-db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the download steps runs, and reaches completion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Deploying Using the Deployer Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set the target talon boards to set up the configuration for. In Jive/Taranta, this would be configured by manually writing the attribute via the UI. Multiple boards can be targeted. With this set, then run the configuration command by calling the generate_config_jsons command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer.targetTalons = target_talon\n",
    "print(f\"Set deployer device to target boards: {deployer.targetTalons}\")\n",
    "print(\"Generating configurations for specified board...\")\n",
    "deployer.generate_config_jsons()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then get the device artifacts from the [artifact repository](https://artefact.skao.int/#browse/browse:helm-internal) by running the command via TANGO. This step may take some time as it downloads multiple devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer.set_timeout_millis(200000)\n",
    "try:\n",
    "    print(\"Starting download of required artifacts...\")\n",
    "    deployer.download_artifacts()\n",
    "except DevFailed as e:\n",
    "    print(e)\n",
    "    print(\n",
    "        \"Timed out, this is likely due to the download taking some time. Check the logs with the code space below after some time to see if it passes.\"\n",
    "    )\n",
    "deployer.set_timeout_millis(4500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that the artifacts downloaded successfully, check that the following returns something like `INFO|Dummy-2|download_fpga_bitstreams|midcbf_deployer.py#418||Finished downloading`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confirm that this returns that artifacts finished downloading:\")\n",
    "!kubectl logs -n $ns ds-deployer-deployer-0 | grep 'Finished downloading'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, configure the TANGO database with all the tango devices downloaded using the ConfigDB command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer.configure_db()\n",
    "print(\"Confirm that the correct TANGO Devices were exported:\")\n",
    "print(*db.get_device_exported(\"*\").value_string, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the devices we'll need to use now exported, proceed to use them for the next steps of starting up the boards and running BITE commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Uploading Controller Settings and Starting the Boards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the required devices are deployed and exported, set up the DeviceProxies for the devices to use in the next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting  proxies to required devices...\")\n",
    "controller = DeviceProxy(\"mid-csp/control/0\")\n",
    "print(controller.status())\n",
    "subarray = DeviceProxy(\"mid-csp/subarray/01\")\n",
    "print(subarray.status())\n",
    "cbf = DeviceProxy(\"mid_csp_cbf/sub_elt/controller\")\n",
    "print(cbf.status())\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running this step and the following steps, ensure that the boards to use in this notebook are checked out!**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then set adminMode to 0 (ONLINE), allowing us to run commands, and set simulationMode to 0 (FALSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set relevant values on the mid-csp controller\n",
    "print(\"Setting admin mode...\")\n",
    "controller.adminMode = 0\n",
    "sleep(1)\n",
    "print(\"Setting simulation mode...\")\n",
    "controller.write_attribute(\"cbfSimulationMode\", sim_mode)\n",
    "controller.cbfSimulationMode = sim_mode\n",
    "sleep(1)\n",
    "if (\n",
    "    controller.read_attribute(\"adminMode\").value == 0\n",
    "    and controller.read_attribute(\"cbfSimulationMode\").value == 0\n",
    "):\n",
    "    print(\"Turned on devices, simulation mode set to FALSE!\")\n",
    "elif (\n",
    "    controller.read_attribute(\"adminMode\").value == 0\n",
    "    and controller.read_attribute(\"cbfSimulationMode\").value == 1\n",
    "):\n",
    "    print(\"Turned on devices, simulation mode set to TRUE.\")\n",
    "else:\n",
    "    print(\"Error, couldn't turn on the device!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the status dashboard, it should now display that all devices are both OFF and that the `simulationstate` is set to the expected state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Next, load in a initial values parameters and pass it to the controller, to do this, read in JSON file and pass it as a DevString to the relevant device command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INIT_SYS_PARAM_FILE, encoding=\"utf-8\") as init_file:\n",
    "    data = json.load(init_file)\n",
    "cbf.InitSysParam(json.dumps(data))\n",
    "print(\"Uploaded Initial system parameters:\")\n",
    "print(cbf.sysParam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, turn ON the Controller by passing it the device to turn on, and letting it run for 55ms to give the boards time to power on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.set_timeout_millis(50000)\n",
    "target = [\"mid_csp_cbf/sub_elt/controller\"]\n",
    "print(\"Sending the command to turn on the selected board and waiting for it to start up...\")\n",
    "controller.On(target)\n",
    "wait_for_tango.wait_for_status(controller, \"ON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(controller.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this step, check with the Taranta dashboard to check that the boards are started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Running BITE Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Running Commands through the BITE Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the BITE tango Device has been deployed via the deployer, use it to configure tests. First, check the device is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bite = DeviceProxy(\"mid_csp_cbf/ec/bite\")\n",
    "print(f\"Current BITE device status (Should be RUNNING): {bite.State()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, use the defaults and simply call the write command for the test configs. This should return the configuration for each board passed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting target board for data generation...\")\n",
    "bite.boards = target_talon\n",
    "bite.bite_mac_address = TARGET_MAC_ADDRESS\n",
    "bite_mode = \"device\"\n",
    "print(\"Generating bite data...\")\n",
    "bite.command_inout(\"generate_bite_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Assigning Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the relevant subarray device to assign resources. First, as with the other devices, establish a DeviceProxy to connect to it. Also read in the assign_resources file to load in using the command. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the loaded data, ensure the right board is selected, modifying the data for the receptor ID based on the Talon board selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data from the file.\n",
    "subarray = DeviceProxy(\"mid-csp/subarray/01\")\n",
    "with open(ASSIGN_CSP_RESOURCES_FILE, encoding=\"utf-8\") as init_file:\n",
    "    config_dict = json.load(init_file)\n",
    "\n",
    "# In order to use the correct receptor, modify the assign_resources data to use the correct receptor based on the board we're using\n",
    "config_dict[\"dish\"][\"receptor_ids\"] = [RECEPTOR_MAP[target_talon - 1]]\n",
    "print(\"Modified config data:\")\n",
    "print(json.dumps(config_dict, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, run the actual command to pass in the resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Assigning CSP resources:\")\n",
    "subarray.AssignResources(json.dumps(config_dict))\n",
    "wait_for_tango.wait_for_state(subarray, \"IDLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 SDP Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, run a few commands to set up the Science Data Processor (SDP), utilizing the sdp namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set up a proxy to the SDP device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp_subarray = DeviceProxy(\"mid-sdp/subarray/01\")\n",
    "sdp_subarray.On()\n",
    "print(f\"SDP device status (should be RUNNING): {sdp_subarray.Status()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, assign resources as with the subarray. As with the csp, map the receptor boards based on our checked out board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ASSIGN_RESOURCES_FILE, encoding=\"utf-8\") as f:\n",
    "    sdp_resources = json.load(f)[\"sdp\"]\n",
    "sdp_resources[\"resources\"][\"receptors\"] = [RECEPTOR_MAP[target_talon - 1]]\n",
    "print(\"modified sdp_resources file...\")\n",
    "print(json.dumps(sdp_resources, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the command to assign resources and wait to get out of the resourcing state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Assigning resources to SDP...\")\n",
    "sdp_subarray.AssignResources(json.dumps(sdp_resources))\n",
    "wait_for_tango.wait_for_state(sdp_subarray, \"IDLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next send the configure command along with the required config file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CONFIGURE_SCAN_FILE, encoding=\"utf-8\") as f:\n",
    "    sdp_configuration = json.load(f)\n",
    "    sdp_configuration = sdp_configuration[\"sdp\"]\n",
    "print(\"SDP scan configuration for this run will be...\")\n",
    "print(json.dumps(sdp_configuration, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Configuring SDP...\")\n",
    "sdp_subarray.Configure(json.dumps(sdp_configuration))\n",
    "wait_for_tango.wait_for_state(sdp_subarray, \"READY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the SDP output via the Scan command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SCAN_FILE, encoding=\"utf-8\") as f:\n",
    "    sdp_scan = json.load(f)\n",
    "    sdp_scan = sdp_scan[\"sdp\"]\n",
    "print(\"SDP scan config:\")\n",
    "print(json.dumps(sdp_scan, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting SDP scan...\")\n",
    "sdp_subarray.Scan(json.dumps(sdp_scan))\n",
    "print(sdp_subarray.obsState.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this step, a pod for receiving visibilities will be launched, grab the IP of this pod and place it in the output_host var in the configure_scan json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the pod name\n",
    "!kubectl -n $ns-sdp get pods | grep vis-receive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then find the IP:\n",
    "vis_pod = \"proc-pb-test-20211111-00059-vis-receive-00-0\"\n",
    "!kubectl -n $ns-sdp describe pod $vis_pod | grep net1 -A 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the IP from this, and write it to a var we'll use later to configure the CSP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using visibility pod, please copy this to the vis_cfg.json\n",
    "output_host = \"10.50.1.30\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this pod, prep for monitoring the pod for when it receives the visibilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this command, then use the output in a separate terminal to enter the correct pod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo kubectl exec -n $ns-sdp -ti $vis_pod -- bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the following commands in this pod to start monitoring for the correct traffic:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "apt update && apt install -y iproute2 tcpdump && tcpdump -i net1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Starting up the CSP Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on the CSP side, load in the corresponding Scan and config files, modifying the config to prep for our test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CONFIGURE_SCAN_FILE, encoding=\"utf-8\") as f:\n",
    "    csp_config = json.load(f)[\"csp\"]\n",
    "with open(SCAN_FILE, encoding=\"utf-8\") as f:\n",
    "    csp_scan = json.load(f)[\"csp\"]\n",
    "# Modify FSP to match selected board\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"fsp_id\"] = target_talon\n",
    "\n",
    "# Write to the JSON to match original config scan file\n",
    "csp_config[\"common\"][\"config_id\"] = \"1 receptor, band 1, 1 FSP, no options\"\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"fsp_id\"] = 1\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"zoom_factor\"] = 1\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"zoom_window_tuning\"] = 450000\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"channel_offset\"] = 0\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"receptors\"] = [RECEPTOR_MAP[target_talon - 1]]\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"output_host\"][0][0] = 0\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"output_host\"][0][1] = output_host\n",
    "\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"output_port\"][0][0] = 0\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"output_port\"][0][1] = 21000\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"output_port\"][0][2] = 1\n",
    "print(\"CSP configuration:\")\n",
    "print(json.dumps(csp_config, indent=1))\n",
    "print(\"==============================\")\n",
    "print(\"CSP scan configuration:\")\n",
    "print(json.dumps(csp_scan, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Observation state: {}\".format(subarray.obsState.name))\n",
    "subarray.Configure(json.dumps(csp_config))\n",
    "wait_for_tango.wait_for_state(subarray, \"READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Observation state: {}\".format(subarray.obsState.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then start LSTV replay, check the logs and get the epoch value to use later (`INFO: start_utc_time_offset = start_utc_time.unix_tai - ska_epoch_tai = <EPOCH VALUE TO COPY>`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bite_mode == \"device\":\n",
    "    print(\"Using the bite device to start lstv replay...\")\n",
    "    bite.start_lstv_replay()\n",
    "else:\n",
    "    print(\"Using the command line function to start lstv replay...\")\n",
    "    !kubectl exec -ti -n $ns ec-bite -- python3 midcbf_bite.py --talon-bite-lstv-replay --boards=$standin_board --input_data=$target_talon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now store this epoch value to configure the delay model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_epoch = 768350073.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the SPFRx, run this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKA_EPOCH = \"1999-12-31T23:59:28Z\"\n",
    "ska_epoch_utc = Time(SKA_EPOCH, scale=\"utc\")\n",
    "ska_epoch_tai = ska_epoch_utc.unix_tai\n",
    "\n",
    "start_utc_time = Time(datetime.utcnow(), scale=\"utc\")\n",
    "target_epoch = start_utc_time.unix_tai - ska_epoch_tai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then load this into the delay model, and change the `epoch` value to the one generated by the BITE LSTV replay start command, and the `receptor` to match our LSTV gen and receptor ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CSP_DELAY_MODEL_FILE, encoding=\"utf-8\") as f:\n",
    "    delay_model = json.load(f)\n",
    "delayModelProxy = DeviceProxy(\"ska_mid/tm_leaf_node/csp_subarray_01\")\n",
    "delay_model[\"receptor_delays\"][0][\"receptor\"] = RECEPTOR_MAP[target_talon - 1]\n",
    "delay_model[\"start_validity_sec\"] = target_epoch\n",
    "print(json.dumps(delay_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Writing delay model...\")\n",
    "delayModelProxy = DeviceProxy(\"ska_mid/tm_leaf_node/csp_subarray_01\")\n",
    "delayModelProxy.write_attribute(\"delayModel\", json.dumps(delay_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then the matching command in the subarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting CSP scan...\")\n",
    "subarray.Scan(json.dumps(csp_scan))\n",
    "print(\"Observation state (Should be SCANNING): {}\".format(subarray.obsState.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the dashboard, the dish should now be in the SCANNING status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Checking Visabilties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the devices scanning and linked, monitor the output via monitoring the network packets that come from it. Use the tcpdump running terminal to check that packet lengths are correct:\n",
    "- UDP, length 136.\n",
    "- UDP, length 740.\n",
    "\n",
    "Also check that the outputs are properly stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once satisfied with the results, stop the scans and shut down the boards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp_subarray.EndScan()\n",
    "subarray.EndScan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subarray.GoToIdle()\n",
    "sleep(10)\n",
    "subarray.ReleaseAllResources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.Off(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the boards are on, use the LRU command to turn them off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're done, free up dev resources on PSI by deleting the ns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete ns $ns\n",
    "!kubectl delete ns $ns-sdp\n",
    "!kubectl get ns | grep ska-mid-psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŽ‰ Congrats, you've now run the Auto Correlation demo!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
