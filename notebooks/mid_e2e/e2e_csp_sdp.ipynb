{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Auto Correlation with Talon Deployer and BITE\n",
    "###### Last Updated: 12/04/24\n",
    "\n",
    "This demo will show the basic operation of auto correlation using both the original docker-based Deployer and BITE commands, as well as the new TANGO device based ones. With this notebook, all TANGO commands and attribute changes are made via a [TANGO DeviceProxy](https://pytango.readthedocs.io/en/stable/client_api/device_proxy.html) but the overall steps should be the same for using the JIVE interface or Taranta web interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First, this notebook assumes you have a running environment launched from a pipeline, in particular it assumes you are running off one launched from the [SKA-mid-psi](https://gitlab.com/ska-telescope/ska-mid-psi) pipeline. Secondly, for ease of dev work, it also assumes you are using a virtual env. This notebook was made with Python 3.10 in mind.\n",
    "\n",
    "Finally, make sure all requirements are installed via [poetry](https://python-poetry.org/docs/basic-usage/#installing-dependencies), and after that we can grab the imports required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "import tango\n",
    "from pytango import Database, DeviceProxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running on PSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To run on PSI, once running the launch step from the PSI pipeline, grab your booted namespace's name. You can run a check on the ns as well to make sure the pods are ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get ns | grep ska-mid-psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl -n ci-ska-mid-psi-1276624051-jaredmda get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in Variables/Checking Taranta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we set the variables we'll need for the run. First the constants that should not need to be changed unless debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --Requried Vars--\n",
    "# Non-SPD namespace\n",
    "ns = \"ci-ska-mid-psi-1276624051-jaredmda\"\n",
    "# The board(s) we will be using for the test.\n",
    "target_board = [1]\n",
    "\n",
    "# --Optional vars--\n",
    "# Change these values if you want to specify a certain slim directory for files\n",
    "slim_fs_config = \"\"\n",
    "slim_vis_config = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAC address for the boards.\n",
    "TARGET_MAC_ADDRESS = \"08:c0:eb:9d:47:78\"\n",
    "# Parent directory to use to grab config files.\n",
    "DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), \"data\")\n",
    "# Config file directories\n",
    "COMMON_CONFIG_FOLDER = os.path.join(DATA_DIR, \"mid_telescope/cbf\")\n",
    "CSP_CONFIG_FOLDER = os.path.join(DATA_DIR, \"mid_telescope/csp\")\n",
    "TMC_CONFIG_FOLDER = os.path.join(DATA_DIR, \"mid_telescope/tmc\")\n",
    "HW_CONFIG_FOLDER = os.path.join(COMMON_CONFIG_FOLDER, \"hw_config\")\n",
    "# For mapping the talon boards to receptor\n",
    "RECEPTOR_MAP = [\"SKA001\", \"SKA036\", \"SKA063\", \"SKA100\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these set, we can now check the taranta dash to monitor the boards as we run through the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://142.73.34.170/\" + ns + \"/taranta/dashboard?id=65e7b6f7b72ec70018cdb16a&mode=run\"\n",
    "print(\n",
    "    \"You can monitor board status using: https://142.73.34.170/{}/taranta/dashboard?id=65e7b6f7b72ec70018cdb16a&mode=run\".format(\n",
    "        ns\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, all components should be in the `disabled` state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First we want to set up the target board that we will be using for the auto correlation. While this can be multiple boards, for now we will only need one. Punch out the board(s) you have access to and set the `target_board` to assign it to be used in future steps.\n",
    "\n",
    "The `TANGO_HOST` will be created based of the namespace you set earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TANGO_HOST = \"databaseds-tango-base.\" + ns + \".svc.cluster.local:10000\"\n",
    "print(\"Will be using HOST: \", TANGO_HOST)\n",
    "os.environ[\"TANGO_HOST\"] = TANGO_HOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load in the locations of local JSON files for configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting files...\")\n",
    "\n",
    "INIT_SYS_PARAM_FILE = os.path.join(COMMON_CONFIG_FOLDER, \"sys_params/initial_system_param.json\")\n",
    "ASSIGN_RESOURCES_FILE = os.path.join(TMC_CONFIG_FOLDER, \"assign_resources.json\")\n",
    "ASSIGN_CSP_RESOURCES_FILE = os.path.join(CSP_CONFIG_FOLDER, \"assign_resources.json\")\n",
    "SCAN_CONFIG_FILE = os.path.join(TMC_CONFIG_FOLDER, \"configure_scan.json\")\n",
    "SCAN_FILE = os.path.join(TMC_CONFIG_FOLDER, \"scan.json\")\n",
    "CSP_DELAY_MODEL_FILE = os.path.join(TMC_CONFIG_FOLDER, \"delay_model.json\")\n",
    "\n",
    "files = [\n",
    "    INIT_SYS_PARAM_FILE,\n",
    "    ASSIGN_RESOURCES_FILE,\n",
    "    ASSIGN_CSP_RESOURCES_FILE,\n",
    "    ASSIGN_CSP_RESOURCES_FILE,\n",
    "    SCAN_CONFIG_FILE,\n",
    "    SCAN_FILE,\n",
    "    CSP_DELAY_MODEL_FILE,\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    if os.path.isfile(file):\n",
    "        print(f\"{file} exists: ✔️\")\n",
    "    else:\n",
    "        print(f\"{file} does not exist ❌\")\n",
    "\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we pass in the SLIM mesh config files by copying them to the namespace, these files should be in the json_files storage folder. Custom files here are not required, but if needed, the following two code blocks can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if slim_fs_config != \"\" and slim_vis_config != \"\":\n",
    "    !\"kubectl cp {fs_config_path} {ns}/ds-cbfcontroller-controller-0:/app/mnt/slim/fs_slim_config.yaml\"\n",
    "    !\"kubectl cp {vis_config_path} {ns}/ds-cbfcontroller-controller-0:/app/mnt/slim/vis_slim_config.yaml\"\n",
    "else:\n",
    "    print(\"SLIM will use defaults for this test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, we will interact with the TANGO devices via a device proxy, which will allow us to pass commands into them as we would in the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the device proxies targeting bite and deployer\n",
    "db = Database()\n",
    "\n",
    "deployer_tango = DeviceProxy(\"mid_csp_cbf/ec/deployer\")\n",
    "# Check the devices initially deployed to the database\n",
    "print(*db.get_device_exported(\"*\").value_string, sep=\"\\n\")\n",
    "# Make sure the deployer device is set to ON\n",
    "deployer_tango.On()\n",
    "print(deployer_tango.state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load in the hardware configuration depending on the talon boards selected. If a higher number board is chosen, we need to use the swapped config file, and then modify the board value to match the swap file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if any(i > 4 for i in target_board):\n",
    "    print(\"Using swap for higher number talons\")\n",
    "    config = \"hw_config_swap_psi.yaml\"\n",
    "    print(\"Modifying target to use lower nums to match swap file\")\n",
    "    target_board = list(map(lambda x: x - 4, target_board))\n",
    "else:\n",
    "    print(\"Using standard HW config\")\n",
    "    config = \"hw_config_psi.yaml\"\n",
    "\n",
    "HW_CONFIG_FILE = os.path.join(HW_CONFIG_FOLDER, config)\n",
    "if os.path.isfile(HW_CONFIG_FILE):\n",
    "    print(\"HW config: ✔️\")\n",
    "else:\n",
    "    print(\"hw config: ❌\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we copy this file into the controller pod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl cp $HW_CONFIG_FILE $ns/ds-cbfcontroller-controller-0:/app/mnt/hw_config/hw_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Using the Command Line (Old Method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the old method for running the deployer commands, we use kubectl's exec function to run commands on the relevant pod, using the deployer script and passing the relevant commands to it as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer_board_target = target_board[0]\n",
    "print(\"Talon board -> {}\".format(deployer_board_target))\n",
    "!kubectl exec -ti -n $ns ec-deployer -- python3 midcbf_deployer.py --generate-talondx-config --boards=$deployer_board_target\n",
    "!kubectl exec -ti -n $ns ec-deployer -- python3 midcbf_deployer.py --download-artifacts\n",
    "!kubectl exec -ti -n $ns ec-deployer -- python3 midcbf_deployer.py --config-db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the download steps runs, and reaches completion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Using the Deployer Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set the target talon boards we want to set up our configuration for. In Jive/Taranta, this would be configured by manually writing the attribute via the UI. Multiple boards can be targeted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer_tango.targetTalons = target_board\n",
    "print(deployer_tango.targetTalons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this set, we can then run the configuration command by calling the generate_config_jsons command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer_tango.generate_config_jsons()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then get the device artifacts from the [artifact repository](https://artefact.skao.int/#browse/browse:helm-internal) by running the command via TANGO. This step may take some time as it downloads multiple devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer_tango.set_timeout_millis(200000)\n",
    "try:\n",
    "    deployer_tango.download_artifacts()\n",
    "except tango.DevFailed as e:\n",
    "    print(e)\n",
    "    print(\n",
    "        \"Timed out, this is likely due to the download taking some time. Check the logs with the code space below after some time to see if it passes.\"\n",
    "    )\n",
    "deployer_tango.set_timeout_millis(4500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that the artifacts downloaded successfully, we want to check that the following returns something like `INFO|Dummy-2|download_fpga_bitstreams|midcbf_deployer.py#418||Finished downloading`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl logs -n $ns ds-deployer-deployer-0 | grep 'Finished downloading'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can configure the TANGO database with all the tango devices we just downloaded using the ConfigDB command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer_tango.configure_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TANGO database should now be configured with all the devices needed for the next step, running the BITE device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*db.get_device_exported(\"*\").value_string, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading Controller Settings and Starting the Boards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the requried devices deployed and exported, we can set up the DeviceProxies for the devices we'll use in the next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_tango = DeviceProxy(\"mid-csp/control/0\")\n",
    "print(control_tango.status())\n",
    "subarray_tango = DeviceProxy(\"mid-csp/subarray/01\")\n",
    "print(subarray_tango.status())\n",
    "CBF_tango = DeviceProxy(\"mid_csp_cbf/sub_elt/controller\")\n",
    "print(CBF_tango.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running this step and the following steps, ensure that you have checked out the boards you have selected to use!**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then set adminMode to 0 (ONLINE), allowing us to run commands, and set simulationMode to 0 (FALSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set relevant values on the mid-csp controller\n",
    "control_tango.adminMode = 0\n",
    "sleep(1)\n",
    "control_tango.write_attribute(\"cbfSimulationMode\", 0)\n",
    "control_tango.cbfSimulationMode = 0\n",
    "\n",
    "if (\n",
    "    control_tango.read_attribute(\"adminMode\").value == 0\n",
    "    and control_tango.read_attribute(\"cbfSimulationMode\").value == 0\n",
    "):\n",
    "    print(\"Set values successfully!\")\n",
    "elif (\n",
    "    control_tango.read_attribute(\"adminMode\").value == 0\n",
    "    and control_tango.read_attribute(\"cbfSimulationMode\").value == 1\n",
    "):\n",
    "    print(\"Set to simulation mode on.\")\n",
    "else:\n",
    "    print(\"Error, couldn't set values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the status dashboard, it should now display that all devices are both OFF and that the simulationstate is FALSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Next, we load in a inital values parameters and pass it to the controller, to do this we read in JSON file and pass it as a DevString to the relevant device command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INIT_SYS_PARAM_FILE, encoding=\"utf-8\") as init_file:\n",
    "    data = json.load(init_file)\n",
    "print(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_result = CBF_tango.InitSysParam(json.dumps(data))\n",
    "print(upload_result[1])\n",
    "print(CBF_tango.sysParam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we turn ON the Controller by passing it the device we want to turn on, and letting it run for 45ms to give the boards time to power on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(control_tango.status())\n",
    "control_tango.set_timeout_millis(50000)\n",
    "target = [\"mid_csp_cbf/sub_elt/controller\"]\n",
    "control_tango.On(target)\n",
    "sleep(55)\n",
    "print(control_tango.status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(control_tango.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this step, check with the Taranta dashboard to check that the boards are started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Commands in BITE through Command Line Arguments (Old Method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the older method for running BITE commands, utilizing kubectl to run python files directly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we configure, specifying the MAC address of the boards and the board # to configure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standin_board = target_board[0]\n",
    "!kubectl exec -ti -n $ns ec-bite -- python3 midcbf_bite.py --talon-bite-config --boards=$standin_board --bite_mac_address=$TARGET_MAC_ADDRESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Commands through the BITE Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the BITE tango Device has been deployed via the deployer, we can use it to configure tests. First we check the device is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bite_tango = DeviceProxy(\"mid_csp_cbf/ec/bite\")\n",
    "# Running this should return RUNNING\n",
    "print(bite_tango.State())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have confirmed it is running, we load in what board we want to configure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bite_tango.boards = target_board\n",
    "bite_tango.bite_mac_address = TARGET_MAC_ADDRESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we can use the defaults and simply call the write command for the test configs. This should return the configuration for each board passed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(bite_tango.command_inout(\"generate_bite_data\"))\n",
    "\n",
    "# For now run the backup\n",
    "standin_board = target_board[0]\n",
    "print(standin_board)\n",
    "!kubectl exec -ti -n $ns ec-bite -- python3 midcbf_bite.py --talon-bite-config --boards=$standin_board --bite_mac_address=$TARGET_MAC_ADDRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl -n $ns logs ds-bite-bite-0 | grep generate_bite_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the bite data generated, we can then start generating LSTV playback data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bite_tango.start_lstv_replay()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then check the logs to ensure the LSTV geneartion runs correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl -n $ns logs ds-bite-bite-0 | grep start_lstv_replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the relevant subarray device to assign resources. First, as with the other devices, we establish a DeviceProxy to connect to it. We also read in the assign_resources file to load in using the command. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the loaded data, we must ensure the right board is selected, modifying the data for the receptor ID based on the Talon board selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data from the file.\n",
    "subarray_tango = DeviceProxy(\"mid-csp/subarray/01\")\n",
    "with open(ASSIGN_CSP_RESOURCES_FILE, encoding=\"utf-8\") as init_file:\n",
    "    config_dict = json.load(init_file)\n",
    "\n",
    "# In order to use the correct receptor, we modify the assign_resources data to use the correct receptor based on the board we're using\n",
    "print(json.dumps(config_dict))\n",
    "config_dict[\"dish\"][\"receptor_ids\"] = list(map(lambda x: RECEPTOR_MAP[x - 1], target_board))\n",
    "print(json.dumps(config_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next,we run the actual command to pass in the resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subarray_tango.AssignResources(json.dumps(config_dict))\n",
    "while subarray_tango.obsState != 2:\n",
    "    pass\n",
    "print(subarray_tango.obsState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDP Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run a few commands to set up the Science Data Processor (SDP), utilizing the sdp namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set up a proxy to the SDP device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp_tango = DeviceProxy(\"mid-sdp/subarray/01\")\n",
    "sdp_tango.On()\n",
    "print(sdp_tango.Status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we assign resources as we did with the subarray, as with the csp, we map the receptor boards based on our checked out board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ASSIGN_RESOURCES_FILE, encoding=\"utf-8\") as f:\n",
    "    sdp_resources = json.load(f)\n",
    "print(json.dumps(sdp_resources))\n",
    "sdp_resources[\"sdp\"][\"resources\"][\"receptors\"] = list(\n",
    "    map(lambda x: RECEPTOR_MAP[x - 1], target_board)\n",
    ")\n",
    "print(json.dumps(sdp_resources))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the command to assign resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp_tango.AssignResources(json.dumps(sdp_resources[\"sdp\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we send the configure command along with the required config file, making sure we are out of the 'RESOURCING' state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while sdp_tango.obsState != 2:\n",
    "    pass\n",
    "print(sdp_tango.obsState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SCAN_CONFIG_FILE, encoding=\"utf-8\") as f:\n",
    "    sdp_configuration = json.load(f)\n",
    "    sdp_configuration = sdp_configuration[\"sdp\"]\n",
    "print(json.dumps(sdp_configuration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp_tango.Configure(json.dumps(sdp_configuration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then start the SDP output via the Scan command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SCAN_FILE, encoding=\"utf-8\") as f:\n",
    "    sdp_scan = json.load(f)\n",
    "    sdp_scan = sdp_scan[\"sdp\"]\n",
    "print(json.dumps(sdp_scan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(sdp_tango.obsState)\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp_tango.Scan(json.dumps(sdp_scan))\n",
    "print(sdp_tango.obsState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this step, a pod for receiving visibilities will be launched, grab the IP of this pod and place it in the output_host var in the configure_scan json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the pod name\n",
    "!kubectl -n $ns-sdp get pods | grep vis-receive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then find the IP:\n",
    "vis_pod = \"proc-pb-test-20211111-00059-vis-receive-00-0\"\n",
    "!kubectl -n $ns-sdp describe pod $vis_pod | grep net1 -A 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the IP from this, and write it to a var we'll use later to configure the CSP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using visibility pod, please copy this to the vis_cfg.json\n",
    "output_host = \"10.50.1.30\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this pod, we will also want to prep for monitoring the pod for when it recivies the visibilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this command, then use the output in a separate terminal to enter the correct pod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo kubectl exec -n $ns-sdp -ti $vis_pod -- bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then run the following commands in this pod to start monitoring for the correct traffic:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "apt update && apt install -y iproute2 tcpdump && tcpdump -i net1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting up the CSP Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on the CSP side we can load in the corresponding Scan and cofig files, modifying the config to prep for our test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SCAN_CONFIG_FILE, encoding=\"utf-8\") as f:\n",
    "    csp_config = json.load(f)\n",
    "    csp_config = csp_config[\"csp\"]\n",
    "with open(SCAN_FILE, encoding=\"utf-8\") as f:\n",
    "    csp_scan = json.load(f)\n",
    "    csp_scan = csp_scan[\"csp\"]\n",
    "# Modify FSP to match selected board\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"fsp_id\"] = target_board[0]\n",
    "\n",
    "# Write to the JSON to match original config scan file\n",
    "csp_config[\"common\"][\"config_id\"] = \"1 receptor, band 1, 1 FSP, no options\"\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"zoom_factor\"] = 1\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"zoom_window_tuning\"] = 450000\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"channel_offset\"] = 14880\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"output_host\"] = [[]]\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"output_host\"][0] = [0, output_host]\n",
    "csp_config[\"cbf\"][\"fsp\"][0][\"output_port\"] = [[0, 21000, 1]]\n",
    "csp_config[\"cbf\"][\n",
    "    \"delay_model_subscription_point\"\n",
    "] = \"ska_mid/tm_leaf_node/csp_subarray_01/delayModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(csp_config))\n",
    "print(json.dumps(csp_scan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Observation state: {}\".format(subarray_tango.obsState))\n",
    "subarray_tango.Configure(json.dumps(csp_config))\n",
    "sleep(5)\n",
    "print(\"Observation state: {}\".format(subarray_tango.obsState))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Observation state: {}\".format(subarray_tango.obsState))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we start LSTV replay, check the logs and get the epoch value to use later (`INFO: start_utc_time_offset = start_utc_time.unix_tai - ska_epoch_tai = <EPOCH VALUE TO COPY>`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl exec -ti -n $ns ec-bite -- python3 midcbf_bite.py --talon-bite-lstv-replay --boards=$standin_board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then store this epoch value to configure the delay model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_epoch = 767924811"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the SPFRx, run this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from astropy.time import Time\n",
    "\n",
    "SKA_EPOCH = \"1999-12-31T23:59:28Z\"\n",
    "ska_epoch_utc = Time(SKA_EPOCH, scale=\"utc\")\n",
    "ska_epoch_tai = ska_epoch_utc.unix_tai\n",
    "\n",
    "start_utc_time = Time(datetime.utcnow(), scale=\"utc\")\n",
    "target_epoch = start_utc_time.unix_tai - ska_epoch_tai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load this into the delay model, and change the `epoch` value to the one generated by the BITE LSTV replay start command, and the `receptor` to match our LSTV gen and receptor ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CSP_DELAY_MODEL_FILE, encoding=\"utf-8\") as f:\n",
    "    delay_model = json.load(f)\n",
    "delayModelProxy = DeviceProxy(\"ska_mid/tm_leaf_node/csp_subarray_01\")\n",
    "delay_model[\"receptor_delays\"][0][\"receptor\"] = RECEPTOR_MAP[target_board[0] - 1]\n",
    "delay_model[\"start_validity_sec\"] = target_epoch\n",
    "print(json.dumps(delay_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayModelProxy.write_attribute(\"delayModel\", json.dumps(delay_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then the matching command in the subarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subarray_tango.Scan(json.dumps(csp_scan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "print(subarray_tango.obsState)\n",
    "# sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subarray_tango.EndScan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Observation state: {}\".format(subarray_tango.obsState))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the dashboard, the dish should now be in the SCANNING status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Visabilties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the devices scanning and linked, we can monitor the output via monitoring the network packets that come from it. Use the tcpdump running terminal to check that packet lengths are correct:\n",
    "- UDP, length 136.\n",
    "- UDP, length 740."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we're satisfied with the results, we can stop the scans and shut down the boards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp_tango.EndScan()\n",
    "# subarray_tango.EndScan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subarray_tango.GoToIdle()\n",
    "sleep(10)\n",
    "subarray_tango.ReleaseAllResources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_tango.Off(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the boards are on, use the LRU command to turn them off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're done, free up dev resources on PSI by deleting your ns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete ns $ns\n",
    "!kubectl delete ns $ns-sdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get ns | grep ska-mid-psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🎉 Congrats, you've now run the Auto Correlator demo!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
