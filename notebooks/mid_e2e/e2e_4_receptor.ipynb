{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a 200Mhz 4-Receptor Correlation Flow\n",
    "###### Last Updated: 15/04/24\n",
    "\n",
    "This notebook will run through running through a 200Mhz receptor correlation, using 4 Talon boards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, ensure you have: \n",
    "* A namespace running from the [SKA-mid-psi](https://gitlab.com/ska-telescope/ska-mid-psi) pipeline deploy step, or a compatible one.\n",
    "* A virtual env with [poetry](https://python-poetry.org/docs/basic-usage/#installing-dependencies) run on it to ensure all requirements are installed.\n",
    "* Python 3.10 and the above venv selected as the interpreter for the notebook. \n",
    "* Four boards (1,2,3,4 or 5,6,7,8) checked out, unless you plan to run in simulation mode.\n",
    "\n",
    "We can then start this notebook by importing the libraries we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "from tango import Database, DevFailed, DeviceProxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will need to wait for a number of stages to be reached by the devices, we use this to wait for device state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spinner = [\"⣾\", \"⣽\", \"⣻\", \"⢿\", \"⡿\", \"⣟\", \"⣯\", \"⣷\"]\n",
    "\n",
    "\n",
    "def wait_for_state(device: DeviceProxy, desired_state, break_on_error=True) -> None:\n",
    "    \"\"\"Poll a tango device until either the given observation state is reached, or it throws an error.\n",
    "    Arguments:\n",
    "    device -- Tango Device to check\n",
    "    desired_state -- The state which to break upon getting (number or state)\n",
    "    break_on_error -- If set to False, will keeping running when getting an error status.\n",
    "    \"\"\"\n",
    "    spinL = 0\n",
    "    poll = 1\n",
    "    while device.obsState != desired_state:\n",
    "        if spinL < len(spinner) - 1:\n",
    "            spinL += 1\n",
    "        else:\n",
    "            spinL = 0\n",
    "        sleep(0.5)\n",
    "        print(\n",
    "            \"\\r\",\n",
    "            f\"{spinner[spinL]} Poll# {poll}: Current state is {device.obsState.name}, waiting for {desired_state}...\",\n",
    "            end=\"\",\n",
    "        )\n",
    "        if device.obsState == 9 and break_on_error:\n",
    "            break\n",
    "        poll += 1\n",
    "    print(f\"\\nFinished with: {device.obsState.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Running on MID PSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the deploy namespace job has been executed in the GitLab pipeline, retrieve your namespace by running the below block and grabbing the namespace with your name. Use this to set the `ns` variable in the python block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get ns | grep ska-mid-psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Loading in Variables/Checking Taranta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we set the variables we'll need for the run. Ensure that `ns`, `target_boards_list` and `simulation_mode` are set as expected, and that you provide the correct config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --Required Vars--\n",
    "# Non-SPD namespace\n",
    "ns = \"\"  # UPDATE THIS FOR RUN\n",
    "# The boards we will be using for the test. Should only use either 1,2,3,4 or 5,6,7,8 to prevent issues with assignment.\n",
    "target_boards_list = []  # UPDATE THIS FOR RUN\n",
    "# Set to 0 for off, 1 for on\n",
    "simulation_mode = 0  # UPDATE THIS FOR RUN\n",
    "\n",
    "# Slim receptor config, leave blank if using default (1 board)\n",
    "slim_fs_config = \"fs_slim_4vcc_1fsp.yaml\"\n",
    "slim_vis_config = \"\"\n",
    "\n",
    "# Delay Model file, set to alt if using one board\n",
    "delay_model_filename = \"delay_model_4r.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `ns` now set, you should be able to check that pods are correctly deployed to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl -n $ns get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set the rest of the vars we need. These should not need to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAC address for the boards.\n",
    "TARGET_MAC_ADDRESS = \"08:c0:eb:9d:47:78\"\n",
    "# Parent directory to use to grab config files.\n",
    "DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), \"data\")\n",
    "# Config file directories\n",
    "COMMON_CONFIG = os.path.join(DATA_DIR, \"mid_telescope/cbf\")\n",
    "CSP_CONFIG = os.path.join(DATA_DIR, \"mid_telescope/csp\")\n",
    "TMC_CONFIG = os.path.join(DATA_DIR, \"mid_telescope/tmc\")\n",
    "HW_CONFIG = os.path.join(COMMON_CONFIG, \"hw_config\")\n",
    "SLIM_CONFIG = os.path.join(COMMON_CONFIG, \"slim_config\")\n",
    "# For mapping the talon boards to receptor\n",
    "RECEPTOR_MAP = [\"SKA001\", \"SKA036\", \"SKA063\", \"SKA100\"]\n",
    "TARGET_BOARDS_STR = \",\".join(str(x) for x in target_boards_list)\n",
    "BITE_MODE = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these set, we can now check the taranta dash to monitor the boards as we run through the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://142.73.34.170/\" + ns + \"/taranta/dashboard?id=65e7b6f7b72ec70018cdb16a&mode=run\"\n",
    "print(\n",
    "    \"You can monitor board status using: https://142.73.34.170/{}/taranta/dashboard?id=660de6afb20f1600120ec597&mode=run\".format(\n",
    "        ns\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, all components should be in the `disabled` state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TANGO_HOST` environment variable will be created based of the namespace you set earlier, and allows us to communicate to the TANGO devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TANGO_HOST = \"databaseds-tango-base.\" + ns + \".svc.cluster.local:10000\"\n",
    "print(\"Will be using HOST: \", TANGO_HOST)\n",
    "os.environ[\"TANGO_HOST\"] = TANGO_HOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Loading Config Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load in the locations of local JSON files for configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting files...\")\n",
    "\n",
    "INIT_SYS_PARAM_FILE = os.path.join(COMMON_CONFIG, \"sys_params/initial_system_param.json\")\n",
    "ASSIGN_RESOURCES_FILE = os.path.join(TMC_CONFIG, \"assign_resources.json\")\n",
    "ASSIGN_CSP_RESOURCES_FILE = os.path.join(CSP_CONFIG, \"assign_resources.json\")\n",
    "CONFIGURE_SCAN_FILE = os.path.join(TMC_CONFIG, \"configure_scan.json\")\n",
    "SCAN_FILE = os.path.join(TMC_CONFIG, \"scan.json\")\n",
    "CSP_DELAY_MODEL_FILE = os.path.join(TMC_CONFIG, delay_model_filename)\n",
    "SLIM_CONFIG_FILE = os.path.join(SLIM_CONFIG, slim_fs_config)\n",
    "\n",
    "files = [\n",
    "    INIT_SYS_PARAM_FILE,\n",
    "    ASSIGN_RESOURCES_FILE,\n",
    "    ASSIGN_CSP_RESOURCES_FILE,\n",
    "    ASSIGN_CSP_RESOURCES_FILE,\n",
    "    CONFIGURE_SCAN_FILE,\n",
    "    SCAN_FILE,\n",
    "    CSP_DELAY_MODEL_FILE,\n",
    "    SLIM_CONFIG_FILE,\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    if os.path.isfile(file):\n",
    "        print(f\"{file} exists: ✔️\")\n",
    "    else:\n",
    "        print(f\"{file} does not exist ❌\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we pass in the SLIM mesh config files by copying them to the namespace, these files should be in the json_files storage folder. Custom files here are not required, but if needed, the following two code block can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if slim_fs_config != \"\":\n",
    "    print(\"Loading custom SLIM fs config\")\n",
    "    !kubectl cp $SLIM_CONFIG_FILE $ns/ds-cbfcontroller-controller-0:/app/mnt/slim/fs_slim_config.yaml\n",
    "else:\n",
    "    print(\"SLIM fs will use defaults for this test.\")\n",
    "if slim_vis_config != \"\":\n",
    "    print(\"Loading custom SLIM vis config\")\n",
    "    !kubectl cp $SLIM_CONFIG_FILE $ns/ds-cbfcontroller-controller-0:/app/mnt/slim/vis_slim_config.yaml\n",
    "else:\n",
    "    print(\"SLIM vis will use default config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load in the hardware configuration depending on the talon boards selected. If the higher number boards are used, we need to use the swapped config file, and then modify each board value to match the swap file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DO NOT mix higher number boards with lower number ones (2,3,4,5), as this will cause issues with the hardware config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if any(i > 4 for i in target_boards_list):\n",
    "    print(\"Using swap for higher number talons\")\n",
    "    config = \"hw_config_swap_psi.yaml\"\n",
    "    print(\"Modifying target to use lower nums to match swap file\")\n",
    "    target_boards_list = list(map(lambda x: x - 4, target_boards_list))\n",
    "\n",
    "else:\n",
    "    print(\"Using standard HW config\")\n",
    "    config = \"hw_config_psi.yaml\"\n",
    "\n",
    "HW_CONFIG_FILE = os.path.join(HW_CONFIG, config)\n",
    "if os.path.isfile(HW_CONFIG_FILE):\n",
    "    print(\"HW config: ✔️\")\n",
    "else:\n",
    "    print(\"hw config: ❌\")\n",
    "TARGET_BOARDS_STR = \",\".join(str(x) for x in target_boards_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, we will interact with the TANGO devices via a device proxy, which will allow us to pass commands into them as we would in the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the device proxies targeting bite and deployer\n",
    "db = Database()\n",
    "\n",
    "deployer = DeviceProxy(\"mid_csp_cbf/ec/deployer\")\n",
    "# Check the devices initially deployed to the database\n",
    "print(\"Currently exported devices:\")\n",
    "print(*db.get_device_exported(\"*\").value_string, sep=\"\\n\")\n",
    "# Make sure the deployer device is set to ON\n",
    "deployer.On()\n",
    "print(deployer.state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we copy this file into the controller pod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl cp $HW_CONFIG_FILE $ns/ds-cbfcontroller-controller-0:/app/mnt/hw_config/hw_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Deploying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Deploying Using the Command Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the old method for generating the talon config, we use kubectl's exec function to run commands on the relevant pod, using the deployer script and passing the relevant commands to it as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Targeting boards: {}\".format(TARGET_BOARDS_STR))\n",
    "!kubectl exec -ti -n $ns ec-deployer -- python3 midcbf_deployer.py --generate-talondx-config --boards=$TARGET_BOARDS_STR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it completes, we can run the deployer device download and configure commands as normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Deploying Using the Deployer Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set the target talon boards we want to set up our configuration for. In Jive/Taranta, this would be configured by manually writing the attribute via the UI. Multiple boards can be targeted. With this variable set on the device, we can then run the configuration command by calling the generate_config_jsons command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer.targetTalons = target_boards_list\n",
    "print(deployer.targetTalons)\n",
    "deployer.generate_config_jsons()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then get the device artifacts from the [artifact repository](https://artefact.skao.int/#browse/browse:helm-internal) by running the command via TANGO. This step may take some time as it downloads multiple devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer.set_timeout_millis(400000)\n",
    "try:\n",
    "    deployer.download_artifacts()\n",
    "except DevFailed as e:\n",
    "    print(e)\n",
    "    print(\n",
    "        \"Timed out, this is likely due to the download taking some time. Check the logs with the code space below after some time to see if it passes.\"\n",
    "    )\n",
    "deployer.set_timeout_millis(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that the artifacts downloaded successfully, we want to check that the following returns something like `INFO|Dummy-2|download_fpga_bitstreams|midcbf_deployer.py#418||Finished downloading`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl logs -n $ns ds-deployer-deployer-0 | grep 'Finished downloading'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can configure the TANGO database with all the tango devices we just downloaded using the ConfigDB command. It should now be configured with all the devices needed for the next step, running the BITE device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer.configure_db()\n",
    "print(\"Currently exported devices:\")\n",
    "print(*db.get_device_exported(\"*\").value_string, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Uploading Controller Settings and Starting the Boards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the requried devices deployed and exported, we can set up the DeviceProxies for the devices we'll use in the next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = DeviceProxy(\"mid-csp/control/0\")\n",
    "print(controller.status())\n",
    "subarray = DeviceProxy(\"mid-csp/subarray/01\")\n",
    "print(subarray.status())\n",
    "cbf = DeviceProxy(\"mid_csp_cbf/sub_elt/controller\")\n",
    "print(cbf.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running this step and the following steps, ensure that you have checked out the boards you have selected to use!**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then set adminMode to 0 (ONLINE), allowing us to run commands, and set simulationMode to 0 (FALSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set relevant values on the mid-csp controller\n",
    "controller.adminMode = 0\n",
    "sleep(1)\n",
    "controller.write_attribute(\"cbfSimulationMode\", simulation_mode)\n",
    "controller.cbfSimulationMode = simulation_mode\n",
    "sleep(1)\n",
    "\n",
    "if (\n",
    "    controller.read_attribute(\"adminMode\").value == 0\n",
    "    and controller.read_attribute(\"cbfSimulationMode\").value == 0\n",
    "):\n",
    "    print(\"Set to simulation mode off.\")\n",
    "elif (\n",
    "    controller.read_attribute(\"adminMode\").value == 0\n",
    "    and controller.read_attribute(\"cbfSimulationMode\").value == 1\n",
    "):\n",
    "    print(\"Set to simulation mode on.\")\n",
    "else:\n",
    "    print(\"Error, couldn't set values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the status dashboard, it should now display that all devices are both OFF and that the simulationstate is FALSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Next, we load in a inital values parameters and pass it to the controller, to do this we read in JSON file and pass it as a DevString to the relevant device command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INIT_SYS_PARAM_FILE, encoding=\"utf-8\") as init_file:\n",
    "    data = json.load(init_file)\n",
    "print(\"Initial system parameter file:\")\n",
    "print(json.dumps(data, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After confirming the file is correct load into the CBF\n",
    "upload_result = cbf.InitSysParam(json.dumps(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we turn ON the Controller by passing it the device we want to turn on, and letting it run for 100s to give the boards time to power on. Before running this step and further ones, consider using [k9s](https://k9scli.io/) in a separate shell to monitor the CBF controller device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(controller.status())\n",
    "controller.set_timeout_millis(100000)\n",
    "target = [\"mid_csp_cbf/sub_elt/controller\"]\n",
    "controller.On(target)\n",
    "if simulation_mode == 1:\n",
    "    sleep(5)\n",
    "else:\n",
    "    sleep(100)\n",
    "print(controller.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this step, check with the Taranta dashboard to check that the boards are started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, for each board, ssh into each of the boards (`ssh root@talon#`), and run the following commands to ensure that the device servers on each are running."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "ps -ef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 BITE Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Running Commands in BITE through Command Line Arguments (Old Method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the older method for running BITE commands, utilizing kubectl to run python files directly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we copy in required files for multi-board LSTV generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CBF_TARGET = \"/app/images/ska-mid-cbf-engineering-console-bite/test_parameters\"\n",
    "CBF_BASE = \"/app/images/ska-mid-cbf-engineering-console-bite\"\n",
    "TEST_DATA = \"test_parameters\"\n",
    "print(os.path.isdir(TEST_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl exec ec-bite -n $ns -- rm -rf $CBF_TARGET\n",
    "!kubectl cp $TEST_DATA $ns/ec-bite:$CBF_BASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we configure, specifying the MAC address of the boards and the boards to configure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl exec -n $ns ec-bite -- python3 midcbf_bite.py --talon-bite-config --boards=$TARGET_BOARDS_STR --bite_mac_address=$TARGET_MAC_ADDRESS --input_data=$TARGET_BOARDS_STR\n",
    "BITE_MODE = \"cmd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Running Commands through the BITE Device Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the BITE TANGO device server has been deployed via the deployer, we can use it to configure tests. First we check the device is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bite = DeviceProxy(\"mid_csp_cbf/ec/bite\")\n",
    "# Running this should return RUNNING\n",
    "print(bite.State())\n",
    "\n",
    "# Set required vars on BITE device, the boards we want to target and the MAC address for them.\n",
    "bite.boards = target_boards_list\n",
    "bite.bite_mac_address = TARGET_MAC_ADDRESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we can use the defaults and simply call the write command for the test configs. This should return the configuration for each board passed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bite.generate_bite_data()\n",
    "BITE_MODE = \"device\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Assigning Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the relevant subarray device to assign resources. First, as with the other devices, we establish a DeviceProxy to connect to it. We also read in the assign_resources file to load in using the command. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the loaded data, we must ensure the right boards are selected, modifying the data for the receptor ID based on the Talon board selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data from the file.\n",
    "subarray = DeviceProxy(\"mid-csp/subarray/01\")\n",
    "with open(ASSIGN_CSP_RESOURCES_FILE, encoding=\"utf-8\") as init_file:\n",
    "    config_dict = json.load(init_file)\n",
    "\n",
    "# In order to use the correct receptor, we modify the assign_resources data to use the correct receptor based on the board we're using\n",
    "config_dict[\"dish\"][\"receptor_ids\"] = list(map(lambda x: RECEPTOR_MAP[x - 1], target_boards_list))\n",
    "print(json.dumps(config_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run the actual command to pass in the resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subarray.AssignResources(json.dumps(config_dict))\n",
    "wait_for_state(subarray, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 SDP Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run a few commands to set up the Science Data Processor (SDP), utilizing the sdp namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up SDP TANGO device proxy\n",
    "sdp = DeviceProxy(\"test-sdp/subarray/01\")\n",
    "sdp.On()\n",
    "print(sdp.Status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we assign resources as we did with the subarray, as with the csp, we map the receptor boards based on our checked out board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ASSIGN_RESOURCES_FILE, encoding=\"utf-8\") as f:\n",
    "    resources_json = json.load(f)\n",
    "resources_json[\"dish\"][\"receptor_ids\"] = list(\n",
    "    map(lambda x: RECEPTOR_MAP[x - 1], target_boards_list)\n",
    ")\n",
    "resources_json[\"sdp\"][\"resources\"][\"receptors\"] = list(\n",
    "    map(lambda x: RECEPTOR_MAP[x - 1], target_boards_list)\n",
    ")\n",
    "\n",
    "sdp_only_json = resources_json[\"sdp\"]\n",
    "print(\"SDP resources JSON:\")\n",
    "print(json.dumps(sdp_only_json, indent=1))\n",
    "print(\"================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After confirming the resource assignment is correct, run the actual argument and wait for device to go to IDLE\n",
    "sdp.AssignResources(json.dumps(sdp_only_json))\n",
    "wait_for_state(sdp, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we send the configure command along with the required config file, making sure we are out of the 'RESOURCING' state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CONFIGURE_SCAN_FILE, encoding=\"utf-8\") as f:\n",
    "    sdp_configuration = json.load(f)\n",
    "    sdp_configuration = sdp_configuration[\"sdp\"]\n",
    "print(\"SDP config JSON:\")\n",
    "print(json.dumps(sdp_configuration))\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the JSON configuration to the device after ensuring it is correct, waiting to ensure it goes to READY\n",
    "sdp.Configure(json.dumps(sdp_configuration))\n",
    "wait_for_state(sdp, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then start the SDP output via the Scan command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SCAN_FILE, encoding=\"utf-8\") as f:\n",
    "    sdp_scan = json.load(f)\n",
    "    sdp_scan = sdp_scan[\"sdp\"]\n",
    "print(\"Scan JSON:\")\n",
    "print(json.dumps(sdp_scan))\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the SDP's scan command after confirming the scan file is as expected\n",
    "sdp.Scan(json.dumps(sdp_scan))\n",
    "print(sdp.obsState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this step, a pod for receiving visibilities will be launched, grab the IP of this pod and place it in the output_host var in the configure_scan json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the pod name\n",
    "!kubectl -n $ns-sdp get pods | grep vis-receive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then find the IP:\n",
    "vis_pod = \"proc-pb-test-20211111-00059-vis-receive-00-0\"\n",
    "!kubectl -n $ns-sdp describe pod $vis_pod | grep net1 -A 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the IP from this, and write it to a var we'll use later to configure the CSP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_host = \"10.50.1.34\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this pod, we will also want to prep for monitoring the pod for when it receives the visibilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this command, then use the output in a separate terminal to enter the correct pod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo kubectl exec -n $ns-sdp -ti $vis_pod -- bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then run the following commands in this pod to start monitoring for the correct traffic:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "apt update && apt install -y iproute2 tcpdump && tcpdump -i net1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Starting up the CSP Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on the CSP side we can load in the corresponding Scan and cofig files, modifying the config to prep for our test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CONFIGURE_SCAN_FILE, encoding=\"utf-8\") as f:\n",
    "    csp_configure_scan = json.load(f)[\"csp\"]\n",
    "with open(SCAN_FILE, encoding=\"utf-8\") as f:\n",
    "    csp_scan = json.load(f)[\"csp\"]\n",
    "csp_configure_scan[\"common\"][\"config_id\"] = \"4 receptor, band 1, 1 FSP, no options\"\n",
    "csp_configure_scan[\"subarray\"][\"subarray_name\"] = \"4 receptors\"\n",
    "# Write FSP and related data\n",
    "csp_configure_scan[\"cbf\"][\"fsp\"][0][\"fsp_id\"] = 1\n",
    "csp_configure_scan[\"cbf\"][\"fsp\"][0][\"zoom_factor\"] = 1\n",
    "csp_configure_scan[\"cbf\"][\"fsp\"][0][\"zoom_window_tuning\"] = 450000\n",
    "csp_configure_scan[\"cbf\"][\"fsp\"][0][\"channel_offset\"] = 0\n",
    "csp_configure_scan[\"cbf\"][\"fsp\"][0][\"receptors\"] = list(\n",
    "    map(lambda x: RECEPTOR_MAP[x - 1], target_boards_list)\n",
    ")\n",
    "csp_configure_scan[\"cbf\"][\"fsp\"][0][\"output_host\"][0][0] = 0\n",
    "csp_configure_scan[\"cbf\"][\"fsp\"][0][\"output_host\"][0][1] = output_host\n",
    "\n",
    "csp_configure_scan[\"cbf\"][\"fsp\"][0][\"output_port\"][0][0] = 0\n",
    "csp_configure_scan[\"cbf\"][\"fsp\"][0][\"output_port\"][0][1] = 21000\n",
    "csp_configure_scan[\"cbf\"][\"fsp\"][0][\"output_port\"][0][2] = 1\n",
    "\n",
    "print(\"Modified CSP scan configuration is:\")\n",
    "print(json.dumps(csp_configure_scan, indent=1))\n",
    "print(\"========================\")\n",
    "print(\"CSP scan file is:\")\n",
    "print(json.dumps(csp_scan, indent=1))\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After confirming the configure scan file is expected, pass to the csp subarray configure command\n",
    "subarray.Configure(json.dumps(csp_configure_scan))\n",
    "sleep(5)\n",
    "print(\"CBF subarray Observation state after running Configure: {}\".format(subarray.obsState))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we start LSTV replay, check the logs and get the epoch value to use later (`INFO: start_utc_time_offset = start_utc_time.unix_tai - ska_epoch_tai = <EPOCH VALUE TO COPY>`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BITE_MODE == \"device\":\n",
    "    print(\"Using the bite device to start lstv replay...\")\n",
    "    bite.start_lstv_replay()\n",
    "elif BITE_MODE == \"cmd\":\n",
    "    !kubectl exec -ti -n $ns ec-bite -- python3 midcbf_bite.py --talon-bite-lstv-replay --boards=$TARGET_BOARDS_STR --input_data=$TARGET_BOARDS_STR\n",
    "else:\n",
    "    print(\"Did you run the configure BITE commands?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then store this epoch value to configure the delay model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_epoch = 768090142.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load this into the delay model, and change the `start_validity_sec` value to the one generated by the BITE LSTV replay start command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CSP_DELAY_MODEL_FILE, encoding=\"utf-8\") as f:\n",
    "    delay_model = json.load(f)\n",
    "delay_model[\"start_validity_sec\"] = target_epoch\n",
    "print(\"Delay model JSON:\")\n",
    "print(json.dumps(delay_model, indent=1))\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then set the delay model we'll be using for the scan, and run the scan on the csp subarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayModelProxy = DeviceProxy(\"ska_mid/tm_leaf_node/csp_subarray_01\")\n",
    "delayModelProxy.write_attribute(\"delayModel\", json.dumps(delay_model))\n",
    "subarray.Scan(json.dumps(csp_scan))\n",
    "print(\"Observation state: {}\".format(subarray.obsState.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the dashboard, the dish should now be in the SCANNING status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Checking Visibilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the devices scanning and linked, we can monitor the output via monitoring the network packets that come from it. Use the tcpdump running terminal to check that packet lengths are correct:\n",
    "- UDP, length 136.\n",
    "- UDP, length 7040."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also check that the visibility pod is writing data. This can be achieved by using k9s to get the logs from receiver pod in your ns, and checking to see that the following logs appear: `Written data for # vis0 fsp_1_channels to row #`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we're satisfied with the results, we can stop the scans and shut down the boards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End scanning on the SDP\n",
    "sdp.EndScan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp.End()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End scanning on the CSP\n",
    "subarray.EndScan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subarray.End()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have the CSP subarray go to the IDLE state and have it release all resources assigned to it.\n",
    "subarray.GoToIdle()\n",
    "subarray.ReleaseAllResources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the controller off.\n",
    "controller.Off(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If you need to, ensure you save any logs you might need, either using k9s or by piping the log output from kubectl log commands to a file. Once you are done using this notebook and the logs, free up dev resources on MID-PSI by deleting your ns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete ns $ns\n",
    "!kubectl delete ns $ns-sdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get ns | grep ska-mid-psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🎉 Congrats, you've now run the Auto Correlator demo!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
