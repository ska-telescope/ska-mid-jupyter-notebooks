{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a 5-Point Calibration Scan Without OSO Using BITE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook adapts the [Five Point Calibration Scan Controls](https://gitlab.com/ska-telescope/ska-jupyter-scripting/-/blob/main/notebooks/observing/MID_five_point_calibration_scan_controls.ipynb?ref_type=heads) notebook to work with PSI. Running this notebook requires a PSI namespace to be spun up with the CI argument `TMC_ENABLED` set to `true`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing all the libraries needed for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from datetime import date\n",
    "from time import sleep\n",
    "\n",
    "from tango import DevFailed, DeviceProxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until notebook clean up is merged need to use this for waiting for state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spinner = [\"⣾\", \"⣽\", \"⣻\", \"⢿\", \"⡿\", \"⣟\", \"⣯\", \"⣷\"]\n",
    "\n",
    "\n",
    "def wait_for_state(device: DeviceProxy, desired_state, break_on_error=True) -> None:\n",
    "    \"\"\"Poll a tango device until either the given observation state is reached, or it throws an error.\n",
    "    Arguments:\n",
    "    device -- Tango Device to check\n",
    "    desired_state -- The state which to break upon getting (number or state)\n",
    "    break_on_error -- If set to False, will keeping running when getting an error status.\n",
    "    \"\"\"\n",
    "    spinL = 0\n",
    "    poll = 1\n",
    "    while device.obsState != desired_state:\n",
    "        if spinL < len(spinner) - 1:\n",
    "            spinL += 1\n",
    "        else:\n",
    "            spinL = 0\n",
    "        sleep(0.5)\n",
    "        print(\n",
    "            \"\\r\",\n",
    "            f\"{spinner[spinL]} Poll# {poll}: Current state is {device.obsState.name}, waiting for {desired_state}...\",\n",
    "            end=\"\",\n",
    "        )\n",
    "        if device.obsState == 9 and break_on_error:\n",
    "            break\n",
    "        poll += 1\n",
    "    print(f\"\\nFinished with: {device.obsState.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Set Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, grab the namespace launched from the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get ns | grep ska-mid-psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And load it into the variables for the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace = \"ci-ska-mid-psi-1365379550-alexschell\"  # set to desired NS\n",
    "simulation_mode = 0  # set to 1 to run in sim mode\n",
    "target_boards_list = [2]  # assign boards\n",
    "test_id = \"talon2 basic gaussian noise\"  # Test to send config from\n",
    "server = \"ska-sdp-kafka.\" + namespace + \".svc.cluster.local:9092\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load all the other vars the notebook will use. These should not need to be changed for this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Qualified Domain Names for the devices to set up proxies\n",
    "CSP_CONTROLLER_FQDN = \"mid-csp/control/0\"\n",
    "CSP_SUBARRAY_FQDN = \"mid-csp/subarray/01\"\n",
    "\n",
    "CENTRAL_NODE_FQDN = \"ska_mid/tm_central/central_node\"\n",
    "LEAF_NODE_SUBARRAY_FQDN = \"ska_mid/tm_leaf_node/csp_subarray01\"\n",
    "TMC_SUBARRAY_FQDN = \"ska_mid/tm_subarray_node/1\"\n",
    "\n",
    "CBF_SUBARRAY_FQDN = \"mid_csp_cbf/sub_elt/subarray_01\"\n",
    "\n",
    "BITE_FQDN = \"mid_csp_cbf/ec/bite\"\n",
    "DEPLOYER_FQDN = \"mid_csp_cbf/ec/deployer\"\n",
    "\n",
    "# Tango host environment variable\n",
    "TANGO_HOST = \"databaseds-tango-base.\" + namespace + \".svc.cluster.local:10000\"\n",
    "\n",
    "# Parent directory to use to grab config files.\n",
    "DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), \"data\")\n",
    "# Config file directories\n",
    "COMMON_CONFIG = os.path.join(DATA_DIR, \"mid_telescope/cbf\")\n",
    "CSP_CONFIG = os.path.join(DATA_DIR, \"mid_telescope/csp\")\n",
    "TMC_CONFIG = os.path.join(DATA_DIR, \"mid_telescope/tmc\")\n",
    "HW_CONFIG = os.path.join(COMMON_CONFIG, \"hw_config\")\n",
    "SLIM_CONFIG = os.path.join(COMMON_CONFIG, \"slim_config\")\n",
    "CBF_INPUT_DIR = os.path.join(COMMON_CONFIG, \"cbf_input_data\")\n",
    "# For mapping the talon boards to receptor\n",
    "RECEPTOR_MAP = [\"SKA001\", \"SKA036\", \"SKA063\", \"SKA100\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set the environment arg for TANGO HOST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Will be using HOST: \", TANGO_HOST)\n",
    "os.environ[\"TANGO_HOST\"] = TANGO_HOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the file paths defined the JSON files can be loaded in and checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting files...\")\n",
    "\n",
    "INIT_SYS_PARAM_FILE = os.path.join(COMMON_CONFIG, \"sys_params/initial_system_param.json\")\n",
    "ASSIGN_RESOURCES_FILE = os.path.join(TMC_CONFIG, \"assign_resources.json\")\n",
    "CONFIGURE_SCAN_FILE = os.path.join(TMC_CONFIG, \"configure_scan.json\")\n",
    "SCAN_FILE = os.path.join(TMC_CONFIG, \"scan.json\")\n",
    "\n",
    "CBF_INPUT_FILE = f\"{CBF_INPUT_DIR}/cbf_input_data.json\"\n",
    "BITE_CONFIG_FILE = f\"{CBF_INPUT_DIR}/bite_config_parameters/bite_configs.json\"\n",
    "FILTERS_FILE = f\"{CBF_INPUT_DIR}/bite_config_parameters/filters.json\"\n",
    "\n",
    "DISH_CONFIG_FILE = f\"{COMMON_CONFIG}/sys_params/load_dish_config.json\"\n",
    "\n",
    "START_CHANNEL = 0\n",
    "END_CHANNEL = 14860\n",
    "START_PORT = 21000\n",
    "\n",
    "SCAN_COMBOS = [[0.0, 5.0], [0.0, -5.0], [5.0, 0.0], [-5.0, 0.0]]\n",
    "\n",
    "files = [\n",
    "    INIT_SYS_PARAM_FILE,\n",
    "    ASSIGN_RESOURCES_FILE,\n",
    "    CONFIGURE_SCAN_FILE,\n",
    "    SCAN_FILE,\n",
    "    CBF_INPUT_FILE,\n",
    "    BITE_CONFIG_FILE,\n",
    "    FILTERS_FILE,\n",
    "    DISH_CONFIG_FILE,\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    if os.path.isfile(file):\n",
    "        print(f\"{file} exists: ✔️\")\n",
    "    else:\n",
    "        print(f\"{file} does not exist ❌\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set up the hw config to match the boards in use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if any(i > 4 for i in target_boards_list):\n",
    "    print(\"Using swap for higher number talons\")\n",
    "    config = \"hw_config_swap_psi.yaml\"\n",
    "    print(\"Modifying target to use lower nums to match swap file\")\n",
    "    target_boards_list = list(map(lambda x: x - 4, target_boards_list))\n",
    "\n",
    "else:\n",
    "    print(\"Using standard HW config\")\n",
    "    config = \"hw_config_psi.yaml\"\n",
    "\n",
    "HW_CONFIG_FILE = os.path.join(HW_CONFIG, config)\n",
    "if os.path.isfile(HW_CONFIG_FILE):\n",
    "    print(\"HW config: ✔️\")\n",
    "else:\n",
    "    print(\"hw config: ❌\")\n",
    "\n",
    "receptor_ids = list(map(lambda x: RECEPTOR_MAP[x - 1], target_boards_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the HW config file exists, it is loaded into the pod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl cp $HW_CONFIG_FILE $namespace/ds-cbfcontroller-controller-0:/app/mnt/hw_config/hw_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Create Device Proxies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the FQDNs set earlier, and with the pod spun up, create device proxies to the devices used and check the connection to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSP Devices\n",
    "csp_controller = DeviceProxy(CSP_CONTROLLER_FQDN)\n",
    "print(f\"CSP Controller: {csp_controller.Status()}\")\n",
    "csp_subarray = DeviceProxy(CSP_SUBARRAY_FQDN)\n",
    "print(f\"CSP Subarray: {csp_subarray.Status()}\")\n",
    "\n",
    "# TMC Devices\n",
    "tmc_central_node = DeviceProxy(CENTRAL_NODE_FQDN)\n",
    "print(f\"Central Node: {tmc_central_node.Status()}\")\n",
    "leaf_node_subarray = DeviceProxy(LEAF_NODE_SUBARRAY_FQDN)\n",
    "print(f\"Leaf Subarray Node: {leaf_node_subarray.Status()}\")\n",
    "tmc_subarray = DeviceProxy(TMC_SUBARRAY_FQDN)\n",
    "print(f\"TMC subarray Node: {tmc_subarray.Status()}\")\n",
    "\n",
    "# Deployer for setup and BITE for data mocking\n",
    "bite = DeviceProxy(BITE_FQDN)\n",
    "deployer = DeviceProxy(DEPLOYER_FQDN)\n",
    "\n",
    "# CBF Device\n",
    "cbf_subarray = DeviceProxy(CBF_SUBARRAY_FQDN)\n",
    "print(f\"CBF subarray: {cbf_subarray.Status()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Downloading Requirements via the Deployer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set the board to deploy to and turn on the deployer device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer.On()\n",
    "deployer.targetTalons = target_boards_list\n",
    "print(deployer.targetTalons)\n",
    "deployer.generate_config_jsons()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once started and configured, the required devices can then be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer.set_timeout_millis(400000)\n",
    "try:\n",
    "    deployer.download_artifacts()\n",
    "except DevFailed as e:\n",
    "    print(e)\n",
    "    print(\n",
    "        \"Timed out, this is likely due to the download taking some time. Check the logs with the code space below after some time to see if it passes.\"\n",
    "    )\n",
    "deployer.set_timeout_millis(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now configure the device database with the downloaded devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer.configure_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Setting up the Devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Set up TMC Central Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now setup the CSP proxy, and load in the relevant values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmc_central_node.adminMode = 0\n",
    "tmc_central_node.simulationMode = simulation_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set relevant values on the mid-csp controller\n",
    "csp_controller.adminMode = 0\n",
    "csp_subarray.adminMode = 0\n",
    "sleep(1)\n",
    "csp_controller.cbfSimulationMode = simulation_mode\n",
    "csp_subarray.SimulationMode = simulation_mode\n",
    "sleep(1)\n",
    "if (\n",
    "    csp_controller.read_attribute(\"adminMode\").value == 0\n",
    "    and csp_controller.read_attribute(\"cbfSimulationMode\").value == 0\n",
    "):\n",
    "    print(\"Set to simulation mode off.\")\n",
    "elif (\n",
    "    csp_controller.read_attribute(\"adminMode\").value == 0\n",
    "    and csp_controller.read_attribute(\"cbfSimulationMode\").value == 1\n",
    "):\n",
    "    print(\"Set to simulation mode on.\")\n",
    "else:\n",
    "    print(\"Error, couldn't set values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next load in the dish config file to the central node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DISH_CONFIG_FILE, encoding=\"utf-8\") as f:\n",
    "    dish_config_json = f.read()\n",
    "tmc_central_node.LoadDishCfg(dish_config_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load in the initial parameters file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INIT_SYS_PARAM_FILE, encoding=\"utf-8\") as init_file:\n",
    "    data = json.load(init_file)\n",
    "print(\"Initial system parameter file:\")\n",
    "print(json.dumps(data, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Turning on the Telescope via TMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, turn the telescope itself on (TelescopeOn may complain about VCC config, have to wait for it to resolve):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmc_central_node.set_timeout_millis(100000)\n",
    "tmc_central_node.TelescopeOn()\n",
    "sleep(100)\n",
    "\n",
    "print(tmc_central_node.status())\n",
    "print(csp_controller.status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Verify device states:\")\n",
    "print(f\"\\tTMC central node: {tmc_central_node.State()}. Should be ON\")\n",
    "print(f\"\\tTMC subarray node: {tmc_subarray.State()}. Should be ON\")\n",
    "print(f\"\\tCSP controller node: {csp_controller.State()}. Should be ON\")\n",
    "print(f\"\\tCSP subarray node: {csp_subarray.State()}. Should be ON\")\n",
    "print(f\"\\tCBF subarray node: {cbf_subarray.State()}. Should be ON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Controlling the 5-Point Scan from TMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set up JSON Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by getting the base file to use to assign resources to TMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ASSIGN_RESOURCES_FILE, encoding=\"utf-8\") as assign_file:\n",
    "    basic_assign_json = json.load(assign_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the config file for TMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CONFIGURE_SCAN_FILE, encoding=\"utf-8\") as config_file:\n",
    "    basic_configure_json = json.load(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now overwrite the vars that need to be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today().strftime(\"%Y%m%d\")\n",
    "random_id = random.randint(0, 99999)\n",
    "beams = [\n",
    "    {\"beam_id\": \"vis0\", \"function\": \"visibilities\"},\n",
    "    {\"beam_id\": \"pss1\", \"search_beam_id\": 1, \"function\": \"pulsar search\"},\n",
    "    {\"beam_id\": \"pss2\", \"search_beam_id\": 2, \"function\": \"pulsar search\"},\n",
    "    {\"beam_id\": \"pst1\", \"timing_beam_id\": 1, \"function\": \"pulsar timing\"},\n",
    "    {\"beam_id\": \"pst2\", \"timing_beam_id\": 2, \"function\": \"pulsar timing\"},\n",
    "    {\"beam_id\": \"vlbi1\", \"vlbi_beam_id\": 1, \"function\": \"vlbi\"},\n",
    "]\n",
    "\n",
    "port_list = []\n",
    "run = 0\n",
    "while run * 20 + START_CHANNEL <= END_CHANNEL:\n",
    "    port_list.append([run * 20 + START_CHANNEL, START_PORT + run])\n",
    "    run += 1\n",
    "\n",
    "EB_ID = f\"eb-testtmc-{today}-{random_id:05d}\"\n",
    "PB_ID = f\"pb-testrealtime-{today}-{random_id:05d}\"\n",
    "\n",
    "# Configure the assign resources JSON for TMC\n",
    "basic_assign_json[\"sdp\"][\"processing_blocks\"][0][\"parameters\"][\"queue_connector_configuration\"][\n",
    "    \"exchanges\"\n",
    "][0][\"source\"][\"servers\"] = server\n",
    "basic_assign_json[\"dish\"][\"receptor_ids\"] = list(\n",
    "    map(lambda x: RECEPTOR_MAP[x - 1], target_boards_list)\n",
    ")\n",
    "basic_assign_json[\"sdp\"][\"execution_block\"][\"beams\"] = beams\n",
    "basic_assign_json[\"sdp\"][\"processing_blocks\"][0][\"pb_id\"] = PB_ID\n",
    "basic_assign_json[\"sdp\"][\"execution_block\"][\"eb_id\"] = EB_ID\n",
    "basic_assign_json[\"sdp\"][\"resources\"][\"receptors\"] = list(\n",
    "    map(lambda x: RECEPTOR_MAP[x - 1], target_boards_list)\n",
    ")\n",
    "\n",
    "# Configure the configuration JSON for TMC\n",
    "basic_configure_json[\"csp\"][\"common\"][\"config_id\"] = \"1 receptor, band 1, 1 FSP, no options\"\n",
    "basic_configure_json[\"csp\"][\"subarray\"][\"subarray_name\"] = \"1 receptor\"\n",
    "\n",
    "# Set the FSP ID to match the board and set networking\n",
    "basic_configure_json[\"csp\"][\"cbf\"][\"fsp\"][0][\"fsp_id\"] = target_boards_list[0]\n",
    "basic_configure_json[\"csp\"][\"cbf\"][\"fsp\"][0][\"frequency_slice_id\"] = target_boards_list[0]\n",
    "\n",
    "print(\"Modified assign json:\")\n",
    "print(json.dumps(basic_assign_json, indent=1))\n",
    "print(\"===================\")\n",
    "print(json.dumps(basic_configure_json, indent=1))\n",
    "print(\"===================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Assign Resources to the Telescope and Configure Subarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use TMC to pass the configurations down to the devices used (SDP,CSP...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmc_subarray.AssignResources(json.dumps(basic_assign_json))\n",
    "wait_for_state(tmc_subarray, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this step, check the -sdp namespace to ensure the vis pod is spun up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the pod name\n",
    "!kubectl -n $namespace-sdp get pods | grep vis-receive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Setup BITE Data and Generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this version of the notebook, BITE is used to generate the data for mocking a scan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load in all the data configs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BITE_CONFIG_FILE, encoding=\"utf-8\") as f:\n",
    "    bite_config_data = json.dumps(json.load(f))\n",
    "    print(\"BITE configs:\\n\")\n",
    "    print(bite_config_data)\n",
    "bite.load_bite_config_data(bite_config_data)\n",
    "sleep(1)\n",
    "\n",
    "with open(FILTERS_FILE, encoding=\"utf-8\") as f:\n",
    "    filter_data = json.dumps(json.load(f))\n",
    "    print(\"Filters:\\n\")\n",
    "    print(filter_data)\n",
    "bite.load_filter_data(filter_data)\n",
    "sleep(1)\n",
    "\n",
    "with open(CBF_INPUT_FILE, encoding=\"utf-8\") as f:\n",
    "    cbf_input_json = json.load(f)[\"cbf_input_data\"][test_id]\n",
    "    cbf_input_data = json.dumps(cbf_input_json)\n",
    "    print(\"CBF Input Data used to generate BITE data:\\n\")\n",
    "    print(cbf_input_data)\n",
    "bite.load_cbf_input_data(cbf_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these loaded, the BITE data can be generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kubectl logs -n $NS ds-bite-bite-0 -f\n",
    "\n",
    "bite.set_timeout_millis(240000)\n",
    "bite.generate_bite_data()\n",
    "bite.set_timeout_millis(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BITE pod can be monitored during this to ensure it correctly produces the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Running the 5-Point Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the scans can actually be run:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Start Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the scan file and augment it to match our needs, then use the configure command to pass it in to the CSP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this is done, start the LSTV replay, making sure to record the epoch value provided by it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bite.start_lstv_replay()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, send the configuration to TMC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmc_subarray.Configure(json.dumps(basic_configure_json))\n",
    "wait_for_state(tmc_subarray, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Run Scan 1: No Offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set up the vis pod to monitor for packets, running this output on the dev server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo kubectl exec -n $namespace-sdp -ti $vis_pod -- bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once in, install `tcpdump` and run it by copying this command to the bash:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "apt update && apt install -y iproute2 tcpdump && tcpdump -i net1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then have the subarray scan without setting an offset, such that it scans at [0,0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_basic_scan_json = {\n",
    "    \"interface\": \"https://schema.skao.int/ska-tmc-scan/2.1\",\n",
    "    \"transaction_id\": \"txn-....-00003\",\n",
    "    \"scan_id\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmc_subarray.Scan(json.dumps(long_basic_scan_json))\n",
    "wait_for_state(cbf_subarray, 5)\n",
    "print(\"Central Scan has started, giving it some time to run...\")\n",
    "sleep(100)\n",
    "tmc_subarray.EndScan()\n",
    "wait_for_state(cbf_subarray, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watch the logs to ensure the proper packet lengths, Once this passes, the offset scans can be run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Run Offset Scans 2-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is currently blocked as reconfiguration causes low-level TANGO memory allocation issues**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, loop through the offset scans, using the combos to set the scan json. For each, configure it by passing in JSON, then scan again, letting it run before stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 4\n",
    "for offset in SCAN_COMBOS:\n",
    "    print(f\"setting offset to: {offset}\")\n",
    "\n",
    "    # Configure for this offset scan\n",
    "    partial_configure_json = {\n",
    "        \"interface\": \"https://schema.skao.int/ska-tmc-configure/2.2\",\n",
    "        \"transaction_id\": f\"txn-....-0000{count}\",\n",
    "        \"scan_id\": count,\n",
    "        \"pointing\": {\"target\": {\"ca_offset_arcsec\": offset[0], \"ie_offset_arcsec\": offset[1]}},\n",
    "        \"tmc\": {\"partial_configuration\": True},\n",
    "    }\n",
    "    print(\"Partial Config to load:\")\n",
    "    print(json.dumps(partial_configure_json, indent=1))\n",
    "    print(\".......\")\n",
    "    leaf_node_subarray.Configure(json.dumps(partial_configure_json))\n",
    "    wait_for_state(cbf_subarray, 4)\n",
    "    sleep(10)\n",
    "    # Send the Scan command along with relevant JSON,incrementing the scan ID and transaction ID\n",
    "    partial_scan_json = {\n",
    "        \"interface\": \"https://schema.skao.int/ska-tmc-scan/2.1\",\n",
    "        \"transaction_id\": f\"txn-....-0000{count+4}\",\n",
    "        \"scan_id\": 2 + count,\n",
    "    }\n",
    "    leaf_node_subarray.Scan(json.dumps(partial_scan_json))\n",
    "    wait_for_state(cbf_subarray, 5)\n",
    "    # let the scan run for a bit...\n",
    "    sleep(200)\n",
    "    leaf_node_subarray.EndScan()\n",
    "    wait_for_state(cbf_subarray, 4)\n",
    "\n",
    "    count += 1\n",
    "    print(\"============================\")\n",
    "print(\"Done offsets!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Cleanup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmc_subarray.GoToIdle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmc_subarray.ReleaseAllResources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmc_subarray.ObsReset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "al_venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
